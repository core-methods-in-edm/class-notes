"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"4UMWGPLH","bookSection","2017","Bergner, Yoav","Measurement and its Uses in Learning Analytics","The Handbook of Learning Analytics","978-0-9952408-0-3","","","http://solaresearch.org/hla-17/hla17-chapter1","Psychological measurement is a process for making warranted claims about states of mind. As such, it typically comprises the following: de ning a construct; specifying a measurement model and (developing) a reliable instrument; analyzing and accounting for various sources of error (including operator error); and framing a valid argument for particular uses of the outcome. Measurement of latent variables is, after all, a noisy endeavor that can neverthe- less have high-stakes consequences for individuals and groups. This chapter is intended to serve as an introduction to educational and psychological measurement for practitioners in learning analytics and educational data mining. It is organized thematically rather than historically, from more conceptual material about constructs, instruments, and sources of measurement error toward increasing technical detail about particular measurement models and their uses. Some of the philosophical differences between explanatory and predictive modelling are explored toward the end.","2017","2019-09-17 21:41:51","2019-09-17 21:41:51","","34-48","","","","","","","","","","","Society for Learning Analytics Research (SoLAR)","Alberta, Canada","","","","","","","","","<p>The article presents an exciting view of the future, where education is ""on the threshold of a data-intensive revolution"". By equipping policymakers and researchers with new powerful forms of evidence gathering analytics, they are given access to a new array of information that has the potential to change the world we live in. But as the author makes clear, such tool also is grounded by epistemological assumptions and pedagogical practices, meaning that we should also be wary of biases and ethical implications concerned with such analytics.</p> <p> </p> <p> </p>","","","","","Lang, Charles; Siemens, George; Wise, Alyssa Friend; Gaševic, Dragan","","","","","","","","","","","","","","","","","","","1","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5RYZ2Z5L","bookSection","2017","Prinsloo, Paul; Slade, Sharon","Ethics and Learning Analytics: Charting the (Un)Charted","The Handbook of Learning Analytics","978-0-9952408-0-3","","","http://solaresearch.org/hla-17/hla17-chapter1","As the field of learning analytics matures, and discourses surrounding the scope, de nition, challenges, and opportunities of learning analytics become more nuanced, there is bene t both in reviewing how far we have come in considering associated ethical issues and in looking ahead. This chapter provides an overview of how our own thinking has developed and maps our journey against broader developments in the  eld. Against a backdrop of technological advances and increasing concerns around pervasive surveillance and the role and unintended consequences of algorithms, the development of research in learning analytics as an ethical and moral practice provides a rich picture of fears and realities. More importantly, we begin to see ethics and privacy as crucial enablers within learning analytics. The chapter brie y locates ethics in learning analytics in the broader context of the forces shaping higher education and the roles of data and evidence before tracking our personal research journey, highlighting current work in the  eld, and concluding by mapping future issues for consideration.","2017","2019-09-17 21:41:51","2019-09-17 21:41:51","","49-57","","","","","","","","","","","Society for Learning Analytics Research (SoLAR)","Alberta, Canada","","","","","","","","","<p>The chapter, which details the perils of ""big data"", might sound cliched by now - but it still contains a few food for thought. I am particularly interested by its presentation of the various approaches and guidelines set forth to ensure ethical data usage, of which I believe transparency is key - so that the students are not only aware of the data being collected but are ensured full access. While there is no easy answer here, I think as frameworks and codes regarding data usage develop we can eventually arrive at a win-win scenario that will benefit all parties.</p>","","","","","Lang, Charles; Siemens, George; Wise, Alyssa Friend; Gaševic, Dragan","","","","","","","","","","","","","","","","","","","1","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6ULQLUA2","bookSection","2017","Brooks, Christopher; Thompson, Craig","Predictive Modelling in Teaching and Learning","The Handbook of Learning Analytics","978-0-9952408-0-3","","","http://solaresearch.org/hla-17/hla17-chapter1","This article describes the process, practice, and challenges of using predictive modelling in teaching and learning. In both the  elds of educational data mining (EDM) and learning analytics (LA) predictive modelling has become a core practice of researchers, largely with a focus on predicting student success as operationalized by academic achievement. In this chapter, we provide a general overview of considerations when using predictive modelling, the steps that an educational data scientist must consider when engaging in the process, and a brief overview of the most popular techniques in the  eld.","2017","2019-09-17 21:41:51","2019-09-17 21:41:51","","61-68","","","","","","","","","","","Society for Learning Analytics Research (SoLAR)","Alberta, Canada","","","","","","","","","<div title=""Page 1""> <div> <div> <div> <p><span style=""text-decoration: underline;""><strong>Chapter 1: Theory and Learning Analytics</strong> </span></p> <p>Learning analytics</p> <p>By design (by accident?) use of LA tools is always aligned with assessment regimes, which are grounded in epistemological assumptions and pedagogical practices</p> <p>Claim analysis</p> <ul> <li>analysis of the implicit or explicit stances taken in the design and developing of technologies</li> <li>productive human-centered method to address key questinos</li> </ul> <p> </p> <div class=""page"" title=""Page 1""> <div class=""section""> <div class=""layoutArea""> <div class=""column""> <p>Anderson (2008) envisaged the death of theory, models, and scientific methods- data will tell us directly as we discern</p> <div title=""Page 1""> <div> <div> <div> <p>when people become aware that their behavior is under surveillance, with potentially important consequences, they may choose to adapt to game the system</p> </div> </div> </div> </div> <div title=""Page 2""> <div> <div> <div> <p>for educators and learners, the interest turns on the ability to gain insight in a timely manner that could improve outcomes.</p> <p> </p> <p><strong>Theory into practice</strong></p> <p>Epistemology-assessment-pedagogy (EPA) tirad</p> <p><strong>EPA Provocations</strong></p> <p><strong>Epistemology </strong></p> <ul> <li><strong>what are we measuring</strong></li> <li><strong>how are we measuring</strong></li> </ul> <p><strong>Pedagogy</strong></p> <ul> <li><strong>why is the knowledge important to us</strong></li> <li><strong>who is the assessment/analytics for</strong></li> </ul> <p><strong>Assessment</strong></p> <ul> <li><strong>where does the assessment happen</strong></li> <li><strong>when does the assessment and feedback occur</strong></li> </ul> <p> </p> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div>","","","","","Lang, Charles; Siemens, George; Wise, Alyssa Friend; Gaševic, Dragan","","","","","","","","","","","","","","","","","","","1","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B497G382","bookSection","2017","Liu, Ren; Koedinger, Kenneth","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","The Handbook of Learning Analytics","978-0-9952408-0-3","","","http://solaresearch.org/hla-17/hla17-chapter1","In the statistical modelling of educational data, approaches vary depending on whether the goal is to build a predictive or an explanatory model. Predictive models aim to  nd a combination of features that best predict outcomes; they are typically assessed by their accuracy in predicting held-out data. Explanatory models seek to identify interpretable causal relationships between constructs that can be either observed or inferred from the data. The vast majority of educational data mining research has focused on achieving pre- dictive accuracy, but we argue that the  eld could bene t from more focus on developing explanatory models. We review examples of educational data mining efforts that have pro- duced explanatory models and led to improvements to learning outcomes and/or learning theory. We also summarize some of the common characteristics of explanatory models, such as having parameters that map to interpretable constructs, having fewer parameters overall, and involving human input early in the model development process.","2017","2019-09-17 21:41:51","2019-09-17 21:41:51","","69-76","","","","","","","","","","","Society for Learning Analytics Research (SoLAR)","Alberta, Canada","","","","","","","","","<div title=""Page 1""> <div> <div> <div> <p><span style=""text-decoration: underline;""><strong>Chapter 6: Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data</strong> </span></p> <p><strong>Predictive vs. Explanatory Model</strong></p> <ul> <li><strong>predictive model</strong> <ul> <li>aim to find a combination of features that best predict outcomes</li> <li>assessed by accuracy in predicting held-out data</li> </ul> </li> <li><strong>explanatory model</strong> <ul> <li>seeks to identify interpretable causal relationships between constructs that can be either observed or inferred from the data</li> </ul> </li> <li>vast majority of educational data mining research has focused on achieving predictive accuracy, but the field could benefit from more focus on developing explanatory model</li> </ul> <p><strong>COGNITIVE MODEL DISCOVERY</strong></p> <div class=""page"" title=""Page 2""> <div class=""section""> <div class=""layoutArea""> <div class=""column""> <ul> <li>cognitive models are an important basis for the instructional design of automated tutors and are important for accurate assessment of learning and knowledge</li> <li>traditional methods requires human input/time consuming<br /> <ul> <li>structured interviews, think-aloud protocols, rational analysis, and</li> </ul> </li> <li>THEREFORE: models based on data-driven techniques that alleviate</li> </ul> <p><strong>Data-driven cognitive model improvement</strong></p> <p><strong>Learning Factor Analysis</strong></p> <div title=""Page 3""> <div> <div> <div> <ul> <li>developed to automate the data-driven method of KC model refinement to further alleviate the problem of time consuming factor</li> </ul> <p><strong>Automated Cognitive Model Discovery Using SimStudent</strong></p> <p><strong>STUDENT GROUPING</strong></p> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div>","","","","","Lang, Charles; Siemens, George; Wise, Alyssa Friend; Gaševic, Dragan","","","","","","","","","","","","","","","","","","","1","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4HHICM2K","journalArticle","2011","Gelman, A; Niemi, J","Statistical graphics: making information clear – and beautiful","Significance","","","","","","2011-09","2019-09-17 21:41:51","2019-09-17 21:41:51","","134-136","","","","","","","","","","","","","","","","","","","","","<p><span style=""text-decoration: underline;""><strong>Statistical graphics: making information clear – and beautiful</strong></span><strong></strong></p> <p><strong>Information visualization (InfoVis)</strong></p> <ul> <li>Statistical graphics <ul> <li>importance shifted from making the graphic beautiful to making it clear</li> </ul> </li> </ul> <p><strong>Visualizations of measles epidemic</strong></p> <ul> <li>Harare, Zimbabwe in the face of measles outbreak from autumn 2009 to 2010</li> </ul> <p><strong>Default graphs in Excel and R</strong></p> <div title=""Page 1""> <div> <div> <div> <ul> <li>plots of the time series of cumulative confirmed measles cases</li> <li>they are labelled and scaled to fill an entire screen. The time series presented here is uncomplicated and could easily fit on a small portion of the page, if the labelling were sized appropriately</li> </ul> <div title=""Page 2""> <div> <div> <div> <p><strong>Constructing a more beautiful and informative summary of data and inferences</strong></p> <ul> <li><strong>2 key decisions</strong> <ul> <li>who is target audience</li> <li>what are you trying to show</li> </ul> </li> <li><strong>guiding principles</strong><br /> <ul> <li>avoid distracting elements</li> <li>use informative color</li> <li>keep the figure simple</li> </ul> </li> </ul> <p><strong>Further graphs for data exploration</strong></p> <ul> <li><strong>another guiding principles</strong> <ul> <li>keep the x-and y-axes on the same scale</li> <li>eliminate repetitive info</li> <li>maintain consistency across plots</li> </ul> </li> </ul> <p> </p> </div> </div> </div> </div> </div> </div> </div> </div>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SDQQSWS2","journalArticle","2012","Gelman, A; Unwin, A","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","","","","","","","2012","2019-09-17 21:41:51","2019-09-17 21:41:51","","","","","","","","","","","","","","","","","","","","","","","<p>The word ""statistics"" carries with it the old world, boring, archaic, rule-based; the word ""information visualization"", however, sounds exciting, flashy, albeit a bit fraudulent. In visualizing our data as practitioners, we must do our best to meet somewhere at the middle, to show the best of both worlds, and in doing so the Gelman article will be a great handbook. Our graphics must take into account the two pillars of discovery and communication goals, being both intuitive and truthful; it must be interesting but not overly flashy. They must be founded by deeply rooted statistical principles while also presenting an attractive and easy-to-understand illustration to the layman audience.</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VA8JGP28","blogPost","2014","Fung, K","Junkcharts Trifecta Checkup: The Definitive Guide","Junkcharts","","","","http://junkcharts.typepad.com/junk_charts/junk-charts-trifecta-checkup-the-definitive-guide.html","","2014","2019-09-17 21:41:51","2019-09-17 21:41:51","","","","","","","","","","","","","","","","","Blog","","","","","","<p>I laughed out loud at the last type presented in the Trifeca checklist, ""graphical disasters"" that fail at all three pillars - the Citibike Chart is very poorly designed both graphically and statistically, and it is impossible to know what question the chart is supposed to be answering. I agree that the three elements presented here - the question, the data, and the visual - are the keys to visual presentation and we should always keep these in mind as practitioners.</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JGT4Z79J","journalArticle","2010","Bowers, Alex J.","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Practical Assessment, Research & Evaluation","","1531-7714","","","School personnel currently lack an effective method to pattern and visually interpret disaggregated achievement data collected on students as a means to help inform decision making. This study, through the examination of longitudinal K-12 teacher assigned grading histories for entire cohorts of students from a school district (n=188), demonstrates a novel application of hierarchical cluster analysis and pattern visualization in which all data points collected on every student in a cohort can be patterned, visualized and interpreted to aid in data driven decision making by teachers and administrators. Additionally, as a proof-of-concept study, overall schooling outcomes, such as student dropout or taking a college entrance exam, are identified from the data patterns and compared to past methods of dropout identification as one example of the usefulness of the method. Hierarchical cluster analysis correctly identified over 80% of the students who dropped out using the entire student grade history patterns from either K-12 or K-8. (Contains 5 figures.)","2010-05","2019-09-17 21:41:51","2019-09-17 21:41:51","2014-09-24 19:31:29","","","7","15","","","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students","","","","","","","en","","","","","ERIC","","","<p><span style=""text-decoration: underline;""><strong>Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis</strong></span></p> <p>Longitudinal K-12 teacher assigned grading histories for entire cohorts of students from school district</p> <p>hierarchical cluster analysis</p> <p>pattern visualization</p> <p>For the aid in data-driven decision making by teachers and administrators</p> <p>Overall schooling outcomes (student dropout, college entrance exam)  - identified from data patterns and compared to past methods of the identification</p> <p> </p> <p>Result: hierarchical cluster analysis correctly identified over 80 percent of students who dropped out using entire student grade history patterns</p>","","http://eric.ed.gov/?id=EJ933686","","data; data analysis; Decision Making; Dropouts; Elementary School Students; Grades (Scholastic); Identification; MULTIVARIATE analysis; School Districts; Secondary School Students","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EK2LRLII","journalArticle","2014","Grunspan, Daniel Z.; Wiggins, Benjamin L.; Goodreau, Steven M.","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","CBE-Life Sciences Education","",", 1931-7913","10.1187/cbe.13-08-0162","http://www.lifescied.org/content/13/2/167","Social interactions between students are a major and underexplored part of undergraduate education. Understanding how learning relationships form in undergraduate classrooms, as well as the impacts these relationships have on learning outcomes, can inform educators in unique ways and improve educational reform. Social network analysis (SNA) provides the necessary tool kit for investigating questions involving relational data. We introduce basic concepts in SNA, along with methods for data collection, data processing, and data analysis, using a previously collected example study on an undergraduate biology classroom as a tutorial. We conduct descriptive analyses of the structure of the network of costudying relationships. We explore generative processes that create observed study networks between students and also test for an association between network position and success on exams. We also cover practical issues, such as the unique aspects of human subjects review for network studies. Our aims are to convince readers that using SNA in classroom environments allows rich and informative analyses to take place and to provide some initial tools for doing so, in the process inspiring future educational studies incorporating relational data.","2014-06-20","2019-09-17 21:41:52","2019-09-17 21:41:52","2014-08-20 20:21:46","167-178","","2","13","","CBE Life Sci Educ","Understanding Classrooms through Social Network Analysis","","","","","","","en","","","","","www.lifescied.org","","","<div title=""Page 1""> <div> <div> <p><span style=""text-decoration: underline;""><strong>Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research</strong> </span></p> </div> </div> </div> <p>Social relationships/interactions</p> <p>How learning relationships form in undergraduate classrooms</p> <p>Impacts that these relationships have on learning outcomes</p> <p><strong>Social Network Analysis (SNA)</strong></p> <ul> <li>tool for investigating questions involving relational data</li> <li>Using SNA in classroom setting allows rich and informative analyses to provide initial tools</li> <li>Can inform our understanding of student network formation in classrooms and the types of impacts these networks have on students</li> <li>Can give a baseline understanding of classroom net- work norms and illuminate major aspects of undergraduate learning</li> <li>Basics: <ul> <li>aims to understand the determinants, structure, and consequences of relationships between actors/nodes</li> </ul> </li> </ul> <p><strong>Network Types</strong></p> <ul> <li><strong>Unipartite/ monopartite/ one-mode</strong> <ul> <li>network consist of only one type of actor</li> </ul> </li> <li><strong>Bipartite/ two-mode</strong> <ul> <li>network consist of 2 types of actor</li> </ul> </li> <li><strong>Undirected</strong> <br /> <ul> <li>ties between actors are inherently bidirectional</li> </ul> </li> <li><strong>Directed</strong> <ul> <li>relational interest of network as an associated direction</li> </ul> </li> <li><strong>Binary ties</strong> <ul> <li>represents whether or not a relation exists</li> </ul> </li> <li><strong>Valued ties</strong> <ul> <li>include additional quantitative info about the relation</li> </ul> </li> </ul> <div title=""Page 2""> <div> <div> <p><strong>Network Data Collection</strong></p> <ul> <li>requires deciding on a time frame for the relationships of interest (changing overtime)</li> <li>how to sample from population <ul> <li>egocentric <ul> <li>focus on sample of individuals and local social environment</li> <li>without explicit attempt to connect the dots</li> </ul> </li> <li>census network <ul> <li>whole networks</li> <li>collect data from bounded population of actors</li> <li>complete picture of the network</li> </ul> </li> </ul> </li> </ul> <p><strong>Network Level Concepts and Measures</strong></p> <ul> <li>Network density <ul> <li>measurement of how many links are observed in a whole network divided by the total number of links that could exist if every actor were connected to every other actor</li> </ul> </li> <li>homophily</li> <li>triad census <ul> <li>simple count of how many different triad types are in network</li> </ul> </li> <li>transitivity <ul> <li>simple local measure of more general set of concepts related to clustering or cohesion <ul> <li>transitive triad</li> <li>cyclical triad</li> </ul> </li> </ul> </li> </ul> <p><strong>Actor-level variables</strong></p> <ul> <li><strong> centrality<br /></strong></li> <li><strong>degree</strong></li> <li><strong>closeness</strong></li> <li><strong>betweeness</strong></li> <li><strong>eigen-vector centrailty</strong></li> </ul> <p>10-wk introductory biology course with 187 students</p> </div> </div> </div> <p>Descriptive analyses of the structure of the network of costudying relationships</p> <div title=""Page 1""> <div> <div> <p>generative processes that create observed study networks between students and also test for an association between network position and success on exams.</p> <p>Practical issues</p> <ul> <li>unique aspects of human subjects review for network studies</li> </ul> </div> </div> </div>","","http://www.lifescied.org/content/13/2/167","Week 2","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BDXDTSCP","blogPost","2014","Young, Jeffrey R.","Why Students Should Own Their Educational Data","The Chronicle of Higher Education Blogs: Wired Campus","","","","http://chronicle.com/blogs/wiredcampus/why-students-should-own-their-educational-data/54329","","2014-08-21","2019-09-17 21:41:52","2019-09-17 21:41:52","2014-08-23 21:32:22","","","","","","","","","","","","","","","","","","","","","","<p><span style=""text-decoration: underline;""><strong>Why Students Should Own Their Educational Data</strong></span></p> <p>Personalized study materials sounds like every learning analyst's dream - as Todd Rose states, the ""average learner"" is but a myth, and tailored learning may solve for discrepancies such as students with high science aptitude but low reading skills. However, sadly as of right now such tailored learning process and its adaptive textbooks sounds cost-prohibitive and difficult to implement in a classroom setting (for a teacher won't be able to tailor to all these individual student skills). Work remains to be done in the area.</p>","","http://chronicle.com/blogs/wiredcampus/why-students-should-own-their-educational-data/54329","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K4XNCRXP","journalArticle","1994","Corbett, Albert T.; Anderson, John R.","Knowledge tracing: Modeling the acquisition of procedural knowledge","User Modeling and User-Adapted Interaction","","0924-1868, 1573-1391","10.1007/BF01099821","http://link.springer.com.ezp-prod1.hul.harvard.edu/article/10.1007/BF01099821","This paper describes an effort to model students' changing knowledge state during skill acquisition. Students in this research are learning to write short programs with the ACT Programming Tutor (APT). APT is constructed around a production rule cognitive model of programming knowledge, called theideal student model. This model allows the tutor to solve exercises along with the student and provide assistance as necessary. As the student works, the tutor also maintains an estimate of the probability that the student has learned each of the rules in the ideal model, in a process calledknowledge tracing. The tutor presents an individualized sequence of exercises to the student based on these probability estimates until the student has ‘mastered’ each rule. The programming tutor, cognitive model and learning and performance assumptions are described. A series of studies is reviewed that examine the empirical validity of knowledge tracing and has led to modifications in the process. Currently the model is quite successful in predicting test performance. Further modifications in the modeling process are discussed that may improve performance levels.","1994-12-01","2019-09-17 21:41:52","2019-09-17 21:41:52","2013-04-21 21:21:19","253-278","","4","4","","User Model User-Adap Inter","Knowledge tracing","","","","","","","en","","","","","link.springer.com.ezp-prod1.hul.harvard.edu","","","<div title=""Page 1""> <div> <div> <p><span style=""text-decoration: underline;""><strong>Knowledge Tracing: Modeling the Acquisition of Procedural Knowledge</strong> </span></p> <p>Modeling students' changing knowledge state during skill acquisition - goals of mastery learning</p> <p><strong>1. ACT Programing Tutor (APT)</strong></p> <ul> <li>constructed around production rule cognitive model of programming knowledge = <em><strong>ideal student model</strong></em></li> <li>allows tutor to solve exercises along the student and provide assistance as necessary</li> <li>tutor maintains an estimate of prob that the student has learned each of the rules in the ideal model <em><strong>knowledge tracing</strong></em></li> <li>tutor presents individualized sequence of exercises to student based on prob estimates until students master each rule</li> </ul> <p><strong>2. Cognitive Model</strong></p> <ul> <li>ACT-R theory of skill knowledge <ul> <li>fundamental distinction between declarative and procedural knowledge <ul> <li>declarative: factual/ experiential/ goal-independent</li> <li>procedural: goal-oriented/ mediates problem solving</li> </ul> </li> <li>assumes  procedural knowledge can be represented as a set of independent production rules that associate problem states and problem solving goals with actions and consequent state changes</li> </ul> </li> </ul> <p><strong>3. Knowledge Tracing and Mastery Learning</strong></p> <ul> <li>Knowledge tracing <ul> <li>assumes 2-state learning model</li> <li>employed in tutor to implement mastery learning</li> </ul> </li> </ul> <p><strong>4. Empirical Evaluations of Knowledge Tracing</strong></p> <ul> <li>internal validity</li> <li>external validity</li> </ul> <p> </p> </div> </div> </div>","","","","Education (general); empirical validity; individual differences; intelligent tutoring systems; Learning; Management of Computing and Information Systems; mastery learning; Multimedia Information Systems; procedural knowledge; Psychology, general; student modeling; User Interfaces and Human Computer Interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XRBGMEUB","conferencePaper","2012","Siemens, George; Baker, Ryan S. J. d.","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Proceedings of the 2Nd International Conference on Learning Analytics and Knowledge","978-1-4503-1111-3","","10.1145/2330601.2330661","http://doi.acm.org/10.1145/2330601.2330661","Growing interest in data and analytics in education, teaching, and learning raises the priority for increased, high-quality research into the models, methods, technologies, and impact of analytics. Two research communities -- Educational Data Mining (EDM) and Learning Analytics and Knowledge (LAK) have developed separately to address this need. This paper argues for increased and formal communication and collaboration between these communities in order to share research, methods, and tools for data mining and analysis in the service of developing both LAK and EDM fields.","2012","2019-09-17 21:41:53","2019-09-17 21:41:53","2015-01-16 03:15:55","252–254","","","","","","Learning Analytics and Educational Data Mining","LAK '12","","","","ACM","New York, NY, USA","","","","","","ACM Digital Library","","","<p><span style=""font-family: 'Segoe UI',sans-serif; color: #24292e;"">Although Educational Data Mining (EDM) and Learning Analytics and Knowledge (LAK) overlap in numerous areas as they share the same goal of “improving education by improving assessments, how problems in education are understood, and how interventions are planned and selected”,  there is a clear distinction between Educational Data Mining (EDM) and Learning Analytics and Knowledge (LAK).</span></p>","","","","Collaboration; educational data mining; learning analytics and knowledge","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BBKGBLXS","book","2015","Zheng, Alice","Evaluating Machine Learning Models","","","","","http://www.oreilly.com/data/free/evaluating-machine-learning-models.csp?intcmp=il-data-free-lp-lgen_free_reports_page","Data science today is a lot like the Wild West: there’s endless opportunity and excitement, but also a lot of chaos and confusion. If you’re new to data science and applied machine learning, evaluating a machine-learning model can seem pretty overwhelming...","2015-09","2019-09-17 21:41:53","2019-09-17 21:41:53","2015-12-15 18:26:39","","","","","","","","","","","","O'Reily Media","Sebastopol, CA","","","","","","","","","<p><span style=""text-decoration: underline;""><strong>Zheng, A. 2015. Evaluating Machine Learning Models. O’Reily Media. Chapter 2: Evaluation Metrics p.7-1</strong></span></p> <p>Evaluation metrics</p> <p>Classification metrics</p> <ul> <li>accuracy</li> <li>confusion matrix</li> <li>per-class accuracy</li> <li>log-loss</li> <li>AUC</li> </ul> <p>Ranking metrics</p> <ul> <li>precision-recall</li> <li>precision-recall curve and F1 score</li> <li>NDCG</li> </ul> <p>Regression metrics</p> <ul> <li>RMSE</li> <li>quantiles of errors</li> <li>""almost correct"" predictions</li> </ul>","","http://www.oreilly.com/data/free/evaluating-machine-learning-models.csp?intcmp=il-data-free-lp-lgen_free_reports_page","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y258NG9C","blogPost","2015","Leong, B; Polonetsky, J","Why Opting Out of Student Data Collection Isn’t the Solution","EdSurge","","","","https://www.edsurge.com/news/2015-03-16-why-opting-out-of-student-data-collection-isn-t-the-solution","In every privacy debate across every industry, the same questions arise about the rights of individuals to “opt-out” of their data being collected or used. So it should come as no surprise that the “when” and “how” of parent and student opt-outs of education data collection or use has become a robust","2015-03-16","2019-09-17 21:41:53","2019-09-17 21:41:53","2016-01-16 16:31:25","","","","","","","","","","","","","","","","","","","","","","<p><span style=""text-decoration: underline;""><strong>Why Opting Out of Student Data Collection Isn’t the Solution</strong></span></p> <p><strong>Rights of individuals to ""opt-out"" of their data being collected or used</strong></p> <p><strong>Fair Information Privacy Principles (FIPPS)</strong></p> <ul> <li>the basis for most privacy laws in the US and around the world</li> <li>requires data collectors to specify the purpose of data collection and get informed consent</li> </ul> <p><strong>How data collection helps students</strong></p> <ul> <li>""primary use"" categories <ul> <li>needed for school to function - data collection is necessary, expected</li> <li>parents have no choice but to provide them because not providing would have their children deprived of educational services</li> <li>basic info about students and parents <ul> <li>grades</li> <li>eligibility for subsidized lunch</li> </ul> </li> <li>Assessing performance through data analysis an essential step to improve education and address areas of concern</li> </ul> </li> </ul> <p><strong>Opt-out Policies</strong><strong></strong></p> <ul> <li>cons: <ul> <li>prevent schools from getting accurate picture of how good of provided education is</li> <li>lack of understanding about challenges and barriers faced by students of diverse backgrounds</li> <li>cannot address the comprehensive needs of all students</li> </ul> </li> </ul> <p><strong>Opting-out is not the solution</strong></p> <ul> <li>providing individual parents with options that disrupt the ability of data to be used for essential educational purposes isn’t the best option</li> <li>Legitimate education policy concerns need to be addressed by fixing these problems for all students, not just the minority who protest by opting out</li> <li>Opt-out rights should be an opportunity for parents to decline uses of data that truly are secondary to the functioning of our educational system – not an opportunity to avoid resolution of education policy issues that affect all students.</li> </ul> <p> </p>","","https://www.edsurge.com/news/2015-03-16-why-opting-out-of-student-data-collection-isn-t-the-solution","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S8BSHZK4","videoRecording","2015","Educause","Why Is Measuring Learning So Difficult?","","","","","https://www.youtube.com/watch?v=_iv8A1pHNYA","Several higher education learning and assessment professionals discuss the difficulties of measuring learning.","2015-08-17","2019-09-17 21:41:53","2019-09-17 21:41:53","2016-01-17 18:50:57","","","","","","","","","","","","","","","","","","","YouTube","","","<p><span style=""text-decoration: underline;""><strong>Why Is Measuring Learning So Difficult?</strong></span></p> <p>Learning is multidimensional, but to capture data we have to simplify it</p> <p>Learning is too broad</p> <p>Learning is personal</p> <p>No reliable, simple indicator that can trust - understanding cannot be measured, but example of things that can be measured is to have students teach other students</p> <p>Social implications/ emotional aspects that is hard for LA platform to capture</p> <p>Measuring competencies is difficult - students taking MOOCs class with all different background levels</p> <p>Achievement and self-efficacy</p> <p>Analytics - devising a medium, reveal to learning what kinds of connections that they are making that they might not be aware of - doorway to suggest what there is possible</p> <p> </p> <p> </p>","","","","Learning; Assessment; Education; educational assessment; EDUCAUSE; Higher Education; learners; Teaching and learning","","","","","","","","","","","","","","","","","","","","","470 seconds","","","","","","","","","","","","","","","","","","","","","","","","",""
"TEE6CWKX","webpage","2016","Weinersmith, Zach","Saturday Morning Breakfast Cereal","","","","","http://www.smbc-comics.com/index.php?id=3978","","2016-01-05","2019-09-17 21:41:53","2019-09-17 21:41:53","2016-01-18 18:17:09","","","","","","","","","","","","","","","","","","","","","","<p>The comic, while hilarious on its own, also raises the society's increasing trend to conflate correlation with causation. ""Correlation is not causation"" is is one of the basic tenets of statistics and we, as practitioners, should always not let our excitement lead us awry as was the case here with the clocks and engineers.</p>","","http://www.smbc-comics.com/index.php?id=3978","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LL4Z3IBZ","conferencePaper","2014","Clow, Doug","Data wranglers: human interpreters to help close the feedback loop","Proceedings of the Fourth International Conference on Learning Analytics And Knowledge","","","","","","2014","2019-09-17 21:41:53","2019-09-17 21:41:53","","49–53","","","","","","","","","","","ACM","","","","","","","","","","<div title=""Page 2""> <div> <div> <p>The paper shows how learning analytics can be used in creating real significant change as was the case of Open University. I found the wranglers' use of both single-loop and double-loop learning particularly interesting. What was ironic, however, was the fact that the overall evaluation of the learning experience - the key reason that the Wranglers were employed in the first place - actually declined slightly after the project (to no fault of the Wranglers, of course). It is a bit bittersweet, then, that learning analytics are fundamentally limited by the external circumstances that surround them, such as funding and other overall policy measures.</p> </div> </div> </div>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HXD8MCXH","magazineArticle","2015","Kucirkova, Natalia; FitzGerald, Elizabeth","Zuckerberg is ploughing billions into 'personalised learning' – why?","The Conversation","","","","http://theconversation.com/zuckerberg-is-ploughing-billions-into-personalised-learning-why-51940","Zuckerburg wants to plough billions into personalised learning, but his way may not be the right way.","2015-12-09","2019-09-17 21:41:53","2019-09-17 21:41:53","2016-01-18 19:14:05","","","","","","","","","","","","","","","","","","","","","","<p><span style=""text-decoration: underline;""><strong>Zuckerberg is ploughing billions into 'personalised learning' – why?</strong></span></p> <p>Zuckerberg's idea of personalized learning is working with students to customise instruction to meet the student’s individual needs and interests” which alludes to how ""human work is replaced by technology, algorithms provide users with content based on an analysis of their past behaviour and demonstrated interests.""</p> <p>Flaws of Zuckerberg's personalized learning</p> <ul> <li>Education is to acquire both general and specific knowledge and skills</li> <li>""while learners may cope poorly with trying to learn in a way that’s not suited to them, in the real world life will not always be so accommodating""</li> <li>Changing interests</li> </ul> <p>Misuse of children's data - privacy risks</p> <p>Benefits of Personalized Learning</p> <p>Increase in motivation - gives children sense of ""ownership and relevance""</p>","","https://theconversation.com/zuckerberg-is-ploughing-billions-into-personalised-learning-why-51940","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"662HJPCT","videoRecording","2015","Georgia Tech","Feature Selection","","","","","https://www.youtube.com/watch?v=8CpRLplmdqE","","2015-02-23","2019-09-17 21:41:54","2019-09-17 21:41:54","2016-01-18 19:18:06","","","","","","","","","","","","Youtube","","","","","","","","","","<p><span style=""text-decoration: underline;""><strong>Feature Selection - Georgia Tech - Machine Learning</strong></span></p> <p>Feature Selection</p> <ul> <li>Knowledge discovery <ul> <li>interpretability and insight</li> </ul> </li> <li>Curse of dimensionality <ul> <li>amount of data you need increase exponentially as you increase the number of features</li> </ul> </li> </ul>","","https://www.youtube.com/watch?v=8CpRLplmdqE","","","","","","","","","","","","","","","","","","","","","","","3:13","","","","","","","","","","","","","","","","","","","","","","","","",""
"UVTUTYYN","bookSection","2016","Hanneman, R.A.; Riddle, M.","Chapter 1: Social Network Data","Introduction to Social Network Methods","","","","http://faculty.ucr.edu/~hanneman/nettext/C1_Social_Network_Data.html","","2016-01-18","2019-09-17 21:41:54","2019-09-17 21:41:54","2016-01-18 20:17:24","","","","","","","","","","","","","","","","","","","","","","<p><span style=""text-decoration: underline;""><strong>Introduction to social network methods</strong></span></p> <p><strong>Social Network Data</strong></p> <p><strong>Nodes</strong></p> <ul> <li>actors</li> </ul> <p><strong>Edges</strong></p> <ul> <li>relations</li> </ul> <p><strong style=""caret-color: #000000; color: #000000; font-family: Arial; font-style: normal; font-variant-caps: normal; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; text-decoration: none;"">Populations, samples, and boundaries</strong></p> <p><strong style=""caret-color: #000000; color: #000000; font-family: Arial; font-style: normal; font-variant-caps: normal; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; text-decoration: none;"">Modality and levels of analysis</strong></p> <ul> <li>Most social network analysts think of individual persons as being embedded in networks that are embedded in networks that are embedded in networks. Network analysts describe such structures as ""multi-modal.""</li> <li>how the individual is embedded within a structure and how the structure emerges from the micro-relations between individual parts. The ability of network methods to map such multi-modal relations is, at least potentially, a step forward in rigor</li> </ul> <p><strong>Relations</strong><strong></strong></p> <ul> <li><strong>Problems</strong> <ul> <li><strong>sampling ties</strong> <ul> <li><strong>full network methods</strong> <ul> <li>we collect information about each actor's ties with all other actors. In essence, this approach is taking a census of ties in a population of actors -- rather than a sample</li> </ul> </li> <li><strong>Snowball methods </strong> <ul> <li>begin with a focal actor or set of actors. Each of these actors is asked to name some or all of their ties to other actors. Then, all the actors named (who were not part of the original list) are tracked down and asked for some or all of their ties. The process continues until no new actors are identified, or until we decide to stop</li> </ul> </li> <li><strong>Ego-centric networks (with alter connections)</strong></li> <li><strong>Ego-centric networks (ego only)<br /></strong></li> </ul> </li> </ul> </li> </ul> <p>Social network data tend to differ from more ""conventional"" survey data in some key ways: network data are often not probability samples, and the observations of individual nodes are not independent. These differences are quite consequential for both the questions of generalization of findings, and for the mechanics of hypothesis testing.</p> <p> </p>","","http://faculty.ucr.edu/~hanneman/nettext/C1_Social_Network_Data.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GFC7MFAW","webpage","2014","Groelmund, Garrett","RStudio Cheat Sheets","RStudio","","","","https://www.rstudio.com/resources/cheatsheets/","","2014-08-01","2019-09-17 21:41:54","2019-09-17 21:41:54","2016-01-19 21:17:28","","","","","","","","","","","","","","","","","","","","","","<p><strong>The R Markdown sheet</strong></p> <p>The R Markdown sheet introduced me to the workings of R and R Studio. I am excited to see how the program functions as I work with it hands-on - the cheat sheet shows that the program is endlessly versatile, with integration to various other platforms (e.g. Latex).</p>","","http://shiny.rstudio.com/articles/rm-cheatsheet.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WDIJCDAE","conferencePaper","2013","san Pedro, Maria Ofelia; Baker, Ryan; Bowers, Alex; Heffernan, Neil","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school","Educational Data Mining 2013","","","","","","2013","2019-09-17 21:41:54","2019-09-17 21:41:54","","","","","","","","","","","","","","","","","","","","","","","<p><span style=""text-decoration: underline;""><strong>Predicting college enrollment from student interaction with an intelligent tutoring system in middle school</strong></span></p> <p>Indicative of student's choice to attend college:</p> <ul> <li>financial resources</li> <li>family background</li> <li>career aspirations</li> <li>academic ability</li> </ul> <p>Not necessarily give sufficient actionable info to intervene</p> <p><strong>educational software and detectors of specific aspects of student learning and engagement = ASSISTment System in NE</strong></p> <ul> <li>can be used to predict college attendance</li> <li>provide more actionable info</li> </ul>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GYP757U5","journalArticle","2012","Greller, Wolfgang; Drachsler, Hendrik","Translating Learning into Numbers: A Generic Framework for Learning Analytics","Journal of Educational Technology & Society","","1176-3647","","http://www.jstor.org/stable/jeductechsoci.15.3.42","ABSTRACT With the increase in available educational data, it is expected that Learning Analytics will become a powerful means to inform and support learners, teachers and their institutions in better understanding and predicting personal learning needs and performance. However, the processes and requirements behind the beneficial application of Learning and Knowledge Analytics as well as the consequences for learning and teaching are still far from being understood. In this paper, we explore the key dimensions of Learning Analytics (LA), the critical problem zones, and some potential dangers to the beneficial exploitation of educational data. We propose and discuss a generic design framework that can act as a useful guide for setting up Learning Analytics services in support of educational practice and learner guidance, in quality assurance, curriculum development, and in improving teacher effectiveness and efficiency. Furthermore, the presented article intends to inform about soft barriers and limitations of Learning Analytics. We identify the required skills and competences that make meaningful use of Learning Analytics data possible to overcome gaps in interpretation literacy among educational stakeholders. We also discuss privacy and ethical issues and suggest ways in which these issues can be addressed through policy guidelines and best practice examples.","2012","2019-09-17 21:41:54","2019-09-17 21:41:54","2016-09-03 18:55:41","42-57","","3","15","","Journal of Educational Technology & Society","Translating Learning into Numbers","","","","","","","","","","","","JSTOR","","","<p><span style=""text-decoration: underline;""><strong>Translating Learning into Numbers: A Generic Framework for Learning Analytics</strong></span></p> <p>The paper is interesting in its presentation of the new design framework for learning analytics. Of the six dimensions mentioned, I find the internal limitations to be a critical, but often overlooked, part of the learning analytics process. The <em>competencies </em>involved in interpretation of the data, both immediate and its far-reaching implications, are pivotal, as is the open mind for the policymakers to <em>accept </em>the outcome of the studies. The six dimensions are inherently connected and so it is important to realize that they work in conjunction and not in isolation.</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CM4JFYLD","bookSection","2006","Kay, Judy; Maisonneuve, Nicolas; Yacef, Kalina; Reimann, Peter","The Big Five and Visualisations of Team Work Activity","Intelligent Tutoring Systems","978-3-540-35159-7 978-3-540-35160-3","","","http://link.springer.com/chapter/10.1007/11774303_20","We have created a set of novel visualisations of group activity: they mirror activity of individuals and their interactions, based upon readily available authentic data. We evaluated these visualisations in the context of a semester long software development project course. We give a theoretical analysis of the design of our visualizations using the framework from the “Big 5” theory of team work as well as a qualitative study of the visualisations and the students’ reflective reports. We conclude that these visualisations provide a powerful and valuable mirroring role with potential, when well used, to help groups learn to improve their effectiveness.","2006-06-26","2019-09-17 21:41:54","2019-09-17 21:41:54","2016-09-03 19:10:12","197-206","","","","","","","Lecture Notes in Computer Science","4053","","","Springer Berlin Heidelberg","","en","©2006 Springer-Verlag Berlin Heidelberg","","","","link.springer.com","","DOI: 10.1007/11774303_20","<p><span style=""text-decoration: underline;""><strong>The Big Five and Visualisations of Team Work Activity</strong></span></p> <p><strong>Visualizations of group activity - mirroring activity of individuals and their interactions</strong><strong></strong></p> <p><strong>Computer-supported collaborative learning (CSCL)</strong></p> <ul> <li>expected beneficial outcomes of teamwork - high motivation, deep involvement in learning, and substantial knowledge gain - often do not materialize</li> </ul> <p><strong>Evaluation of the visualizations in context of a semester long software development project course </strong></p> <p><strong>Theoretical analysis of design of visualizations using the framework from the ""Big 5"" theory of team work as well as quantitative study of the visualizations and students' reflective reports</strong></p> <ul> <li><strong>Big 5 component of teamwork</strong> <ul> <li><strong>team leadership</strong><br /> <ul> <li>facilitate team problem solving</li> <li>provide performance expectations and acceptable interaction patterns</li> <li>synchronize and combine individual team member contributions see and evaluate information that affects team functioning</li> </ul> </li> <li><strong>mutual performance monitoring</strong> <ul> <li>identifying mistakes and lapses in other team member's actions</li> </ul> </li> <li><strong>backup behavior</strong> <ul> <li>recognition of workload distribution problem in the team</li> <li>shifting work to underutilized members</li> </ul> </li> <li><strong>adaptability</strong> <ul> <li>identify cues of change, assign meaning to it, develop new plan to deal with it</li> </ul> </li> <li><strong>team orientation</strong> <ul> <li>increased task involvement, information sharing, strategising and goal setting</li> </ul> </li> </ul> </li> <li><strong>3 coordinating mechanisms</strong> <ul> <li>shared mental models</li> <li>mutual trust</li> <li>closed-loop communication</li> </ul> </li> </ul> <p><strong>Overview of Visualizations</strong></p> <ul> <li><strong>Activity Radar</strong></li> <li><strong>Interaction Network </strong> <ul> <li>based on Social Network Analysis</li> <li>capturing relationships and flows between entities</li> <li>nodes (users) and edges(interaction)</li> </ul> </li> <li><strong>Wattle Tree</strong> <br /> <ul> <li>each user's activity shown in climbing vertical tree <ul> <li>tree start: when user performs an action</li> <li>size = size of contribution<strong></strong><strong></strong></li> </ul> </li> </ul> </li> </ul> <p><strong>Conclusion: </strong></p> <ul> <li>Visualizations provide powerful and valuable mirroring role with potential to help groups learn to improve their effectiveness</li> </ul>","","https://link.springer.com/chapter/10.1007/11774303_20","","Multimedia Information Systems; User Interfaces and Human Computer Interaction; Artificial Intelligence (incl. Robotics); Computers and Education; Information Systems Applications (incl. Internet)","Ikeda, Mitsuru; Ashley, Kevin D.; Chan, Tak-Wai","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S59YPLKQ","journalArticle","2015","Konstan, Joseph A.; Walker, J. D.; Brooks, D. Christopher; Brown, Keith; Ekstrand, Michael D.","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","ACM Trans. Comput.-Hum. Interact.","","1073-0516","10.1145/2728171","http://doi.acm.org/10.1145/2728171","","2015-04","2019-09-17 21:41:55","2019-09-17 21:41:55","2016-09-03 20:38:02","10:1–10:23","","2","22","","","Teaching Recommender Systems at Large Scale","","","","","","","","","","","","ACM Digital Library","","","<div title=""Page 1""> <div> <div> <p><span style=""text-decoration: underline;""><strong>Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC</strong> </span></p> <div title=""Page 1""> <div> <div> <ul> <li>Open online Introduction to Recommender Systems through Coursera</li> <li>For-credit version of the course on-campus using the Coursera platform</li> <li>Flipped classroom instruction model.</li> </ul> <p><strong>Methods:</strong></p> <ul> <li>surveys of demographics</li> <li>self-assessed skills</li> <li>learning intent</li> <li>knowledge-assessment tool specifically for the subject matter in this course, administering it before and after the course to measure learning, and again 5 months later to measure retention</li> <li>tracked students through the course, including separating out students enrolled for credit from those enrolled only for the free, open course</li> </ul> <p><strong>Result:</strong></p> <ul> <li>Students had significant knowledge gains across all levels of prior knowledge and across all demographic categories.</li> <li>The main predictor of knowledge gain was effort expended in the course.</li> <li>Students also had significant knowledge retention after the course.</li> <li>Both of these results are limited to the sample of students who chose to complete our knowledge tests. <ul> <li>Student completion of the course was hard to predict, with few factors contributing predictive power; the main predictor of completion = intent to complete</li> <li>Students who chose a concepts-only track with hand exercises achieved the same level of knowledge of recommender systems concepts as those who chose a programming track and its added assignments, though the programming students gained additional programming knowledge.</li> </ul> </li> <li>Based on the limited data we were able to gather, face-to-face students performed as well as the online-only students or better; they preferred this format to traditional lecture for reasons ranging from pure convenience to the desire to watch videos at a different pace (slower for English language learners; faster for some native English speakers).</li> </ul> </div> </div> </div> </div> </div> </div>","","","","learning assessment; Massively Online Open Course (MOOC)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EPJKARSI","bookSection","2013","Desmarais, Michel C.; Naceur, Rhouma","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","Artificial Intelligence in Education","978-3-642-39111-8 978-3-642-39112-5","","","http://link.springer.com/chapter/10.1007/978-3-642-39112-5_45","Uncovering the right skills behind question items is a difficult task. It requires a thorough understanding of the subject matter and of the cognitive factors that determine student performance. The skills definition, and the mapping of item to skills, require the involvement of experts. We investigate means to assist experts for this task by using a data driven, matrix factorization approach. The two mappings of items to skills, the expert on one side and the matrix factorization on the other, are compared in terms of discrepancies, and in terms of their performance when used in a linear model of skills assessment and item outcome prediction. Visual analysis shows a relatively similar pattern between the expert and the factorized mappings, although differences arise. The prediction comparison shows the factorization approach performs slightly better than the original expert Q-matrix, giving supporting evidence to the belief that the factorization mapping is valid. Implications for the use of the factorization to design better item to skills mapping are discussed.","2013-07-09","2019-09-17 21:41:55","2019-09-17 21:41:55","2016-09-03 20:44:11","441-450","","","","","","","Lecture Notes in Computer Science","7926","","","Springer Berlin Heidelberg","","en","©2013 Springer-Verlag Berlin Heidelberg","","","","link.springer.com","","DOI: 10.1007/978-3-642-39112-5_45","<p><strong>A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices</strong></p> <p>data driven, matrix factorization approach</p> <p><strong>Intro</strong></p> <p>Mapping items to latent skills - difficult</p> <p><strong>Skills Modeling, Q-Matrices and Matrix Factorization</strong></p> <p>2 mappings of items to skills (1) expert and 2) matrix factorization) are compared in terms of discrepancies and in terms of their performance when used in a linear model of skills assessment and item outcome prediction</p> <ol> <li><strong>Linear Models</strong> <ul> <li>put to the task of assessing student skills mastery</li> <li>factorization methods</li> </ul> </li> <li><strong>Results Matrix, Q matrix, and skills matrix</strong></li> </ol> <p><strong>Comparing Q-matrix induced from data with an expert defined matrix</strong></p> <ol> <li>Comparison issues and principle of the proposed method</li> <li>Alternate Least-Square Factorization (ALS)</li> </ol> <p>Result</p> <ul> <li>relatively small pattern between expert and the factorized mapping (although differences arise)</li> <li>factorization approach performs slightly better than the original expert Q matrix <ul> <li>supporting evidence to the belief that the factorization mapping is valid</li> </ul> </li> </ul>","","https://link.springer.com/chapter/10.1007/978-3-642-39112-5_45","","User Interfaces and Human Computer Interaction; Artificial Intelligence (incl. Robotics); Computers and Education; Information Systems Applications (incl. Internet); alternating least squares matrix factorization; Cognitive modeling; Educational Technology; latent skills; Pedagogic Psychology; skills assessment; Student models","Lane, H. Chad; Yacef, Kalina; Mostow, Jack; Pavlik, Philip","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CHNI4D4G","book","2015","Matsuda, Noboru; Furukawa, Tadanobu; Bier, Norman; Faloutsos, Christos","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","","","","","http://eric.ed.gov/?id=ED560513","How can we automatically determine which skills must be mastered for the successful completion of an online course? Large-scale online courses (e.g., MOOCs) often contain a broad range of contents frequently intended to be a semester's worth of materials; this breadth often makes it difficult to articulate an accurate set of skills and knowledge (i.e., a skill model, or the QMatrix). We have developed an innovative method to discover skill models from the data of online courses. Our method assumes that online courses have a pre-defined skill map for which skills are associated with formative assessment items embedded throughout the online course. Our method carefully exploits correlations between various parts of student performance, as well as in the text of assessment items, to build a superior statistical model that even outperforms human experts. To evaluate our method, we compare our method with existing methods (LFA) and human engineered skill models on three Open Learning Initiative (OLI) courses at Carnegie Mellon University. The results show that (1) our method outperforms human-engineered skill models, (2) skill models discovered by our method are interpretable, and (3) our method is remarkably faster than existing methods. These results suggest that our method provides a significant contribution to the evidence-based, iterative refinement of online courses with a promising scalability. [For complete proceedings, see ED560503.]","2015-06","2019-09-17 21:41:55","2019-09-17 21:41:55","2016-09-03 20:48:57","","","","","","","Machine Beats Experts","","","","","International Educational Data Mining Society","","en","","","","","ERIC","","","<div title=""Page 1""> <div> <div> <p><span style=""text-decoration: underline;""><strong>Machine beats experts: Automatic discovery of skill models for data-driven online course refinement</strong> </span></p> <p><strong>Large-scale online courses<br /></strong></p> <ul> <li>contain a broad range of contents frequently intended to be semester's worth of materials <ul> <li>difficult to articulate accurate set of skills and knowledge <ul> <li>Q-matrix</li> </ul> </li> </ul> </li> </ul> <p><strong>So developed innovative method to discover skill models from data of online courses</strong></p> <ul> <li>assumption: <ul> <li>online courses have pre-defined skill map for which skills are associated with formative assessment items</li> </ul> </li> <li>Exploits correlations between parts of student performance</li> <li>Compared existing method (LFA) and human engineered skill models on Open Learning Initiative (OLI)</li> </ul> <p><strong>Result:</strong></p> <ul> <li>the method proposed better than human-engineered skill models</li> <li>skill models discovered by the model can be interpreted</li> <li>method is faster than existing methods</li> </ul> <p> </p> </div> </div> </div>","","http://eric.ed.gov/?id=ED560513","","data; Automation; Comparative Analysis; Correlation; Formative Evaluation; models; Online Courses; Skills","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PC5834XM","conferencePaper","2008","Cortez, Paulo; Silva, Alice Maria Gonçalves","Using data mining to predict secondary school student performance","Proceedings of 5th Annual Future Business Technology Conference","978-90-77381-39-7","","","http://repositorium.sdum.uminho.pt/handle/1822/8024","Although the educational level of the Portuguese population has improved in the last decades, the statistics keep Portugal at Europe’s tail end due to its high student failure rates. In particular, lack of success in the core classes of Mathematics and the Portuguese language is extremely serious. On the other hand, the fields of Business Intelligence (BI)/Data Mining (DM), which aim at extracting high-level knowledge from raw data, offer interesting automated tools that can aid the education domain. The present work intends to approach student achievement in secondary education using BI/DM techniques. Recent real-world data (e.g. student grades, demographic, social and school related features) was collected by using school reports and questionnaires. The two core classes (i.e. Mathematics and Portuguese) were modeled under binary/five-level classification and regression tasks. Also, four DM models (i.e. Decision Trees, Random Forest, Neural Networks and Support Vector Machines) and three input selections (e.g. with and without previous grades) were tested. The results show that a good predictive accuracy can be achieved, provided that the first and/or second school period grades are available. Although student achievement is highly influenced by past evaluations, an explanatory analysis has shown that there are also other relevant features (e.g. number of absences, parent’s job and education, alcohol consumption). As a direct outcome of this research, more efficient student prediction tools can be be developed, improving the quality of education and enhancing school resource management.","2008-04","2019-09-17 21:41:55","2019-09-17 21:41:55","2016-09-04 01:23:19","","","","","","","","","","","","EUROSIS","Porto, Spain","eng","openAccess","","","","repositorium.sdum.uminho.pt","","","<p><span style=""text-decoration: underline;""><strong>Using data mining to predict secondary school student performance</strong></span></p> <p>Automated tools to analyze the raw data and extract interesting high-level information for decision maker</p> <p>Education good for Business Intelligence (BI)/Data Mining (DM) techniques - multiple sources of data (traditional data bases + online web pages) + diverse interest groups (students, teachers, administrators, alumni)</p> <p>Real-world data (student grades, demographic, social and school related features) from Portuguese secondary schools collected by using school reports and questionnaire</p> <p>Mathematics and Portuguese class (core classes) modeled under</p> <ul> <li>3 DM goals <ul> <li>binary classification (pass/fail)</li> <li>classification with 5 levels</li> <li>regression - numeric output ranging between 0 and 20</li> </ul> </li> </ul> <p>For each of these approaches:</p> <ul> <li>4 DM models - Decision Trees, Random Forest, Neural Networks and Support Vector Machines</li> <li>3 Input selections: with and without previous grades</li> </ul> <p>Result:</p> <ul> <li>student achievement highly influenced by past evaluations <ul> <li>other relevant features such as number of absences, parents' education and job, alcohol consumption affect the achievement as well</li> </ul> </li> </ul>","","http://repositorium.sdum.uminho.pt/handle/1822/8024","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","5th Annual Future Business Technology Conference","","","","","","","","","","","","","","",""
"GX4HQNBF","journalArticle","2008","Baker, Ryan S. J. d; Corbett, Albert T.; Roll, Ido; Koedinger, Kenneth R.","Developing a generalizable detector of when students game the system","User Modeling and User-Adapted Interaction","","0924-1868, 1573-1391","10.1007/s11257-007-9045-6","http://link.springer.com/article/10.1007/s11257-007-9045-6","Some students, when working in interactive learning environments, attempt to “game the system”, attempting to succeed in the environment by exploiting properties of the system rather than by learning the material and trying to use that knowledge to answer correctly. In this paper, we present a system that can accurately detect whether a student is gaming the system, within a Cognitive Tutor mathematics curricula. Our detector also distinguishes between two distinct types of gaming which are associated with different learning outcomes. We explore this detector’s generalizability, and find that it transfers successfully to both new students and new tutor lessons.","2008-01-23","2019-09-17 21:41:56","2019-09-17 21:41:56","2016-09-04 01:34:49","287-314","","3","18","","User Model User-Adap Inter","","","","","","","","en","","","","","link.springer.com","","","<p><span style=""text-decoration: underline;""><strong>Developing a generalizable detector of when students game the system</strong> </span></p> <p><strong>game the system</strong></p> <ul> <li>attempt to succeed in the environment by exploiting properties of the system rather than learning the material</li> <li>gaming behavior is associated with significantly poorer learning in Cognitive Tutor classes</li> <li>gaming is a fairly robust construct, present across many intelligent tutoring systems.</li> </ul> <p><strong>Developed a system that can </strong></p> <ul> <li>accurately detect whether a student is gaming the system within Cognitive Tutor mathematics curricula</li> <li>distinguish between two distinct types of gaming associated with different learning outcomes</li> <li>generalize to new tutor system</li> <li>examples: Baker et al.’s (2004) Gaming Detector, and Aleven et al.’s (2004) Help-Seeking Tutor Agent </li> </ul>","","https://link.springer.com/article/10.1007/s11257-007-9045-6","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VR4GSKDE","book","2014","Baker, R","Big Data in Education","","","","","","","2014","2019-09-17 21:41:56","2019-09-17 21:41:56","","","","","","","","","","","","","","New York, NY","","","","","","","","","<p><span style=""text-decoration: underline;""><strong>1.1 Introduction</strong></span></p> <p><strong>Educational Data Mining and Learning Analytics</strong></p> <p><strong>Where do methods come from</strong></p> <ul> <li>Data mining or machine learning</li> <li>Psychometrics or traditional statistics</li> </ul> <p><strong>Prediction</strong></p> <ul> <li>Develop a model which can infer a single aspect of the data <strong>predictive variable </strong>from some combination of other aspects of the data <strong>predictor variables</strong></li> </ul> <p><strong>Structure Discovery</strong></p> <p><strong>Relationship Mining</strong></p> <p><strong>Discovery with Model</strong></p> <p><strong>PSLC DataShop</strong></p>; <p><span style=""text-decoration: underline;""><strong>1.3 Classifiers 1</strong> </span></p> <p><strong>Prediction</strong></p> <p><strong>Classification</strong></p> <ul> <li>a type of prediction model</li> <li>labels</li> <li>thing you want to predict is categorical <ul> <li>correct/long</li> <li>help request/ worked example request/ attempt to solve</li> <li>etc.</li> </ul> </li> <li>Labels come from various sources</li> <li>associated with each label are set of features which maybe you can use to predict the label</li> <li>Basic idea: determine which features, in which combination, can predict the label</li> </ul> <p><strong>Domain Specificity</strong></p> <ul> <li>specific algorithms work better for specific domains and problems</li> </ul> <p><strong>Useful algorithms</strong></p> <ul> <li>step regression</li> <li>logistic regression</li> <li>J48/C4.5 Decision Trees</li> <li>JRip Decision rules</li> <li>K* Instance-Based Classifiers</li> </ul> <p><strong>Step Regression</strong></p> <ul> <li>used for binary classification (0,1)</li> <li>Fits a linear regression function <ul> <li>select parameters</li> <li>assign weight to each parameter</li> <li>computes a numerical values</li> <li>then all values below 0.5 are treated as 0 and all values greater or equal to 0.5 are treated as 1</li> </ul> </li> <li>Cons: <ul> <li>lack of closed form expression</li> </ul> </li> <li>Pros <ul> <li>conservative</li> </ul> </li> </ul> <p><strong>Logistic Regression</strong></p> <ul> <li>used for binary classification (0,1)</li> <li>given a specific set of values of predictor variables</li> <li>fits logistic function to data to find out the frequency/odds of a specific value of the dependent variable</li> <li>Pros: <ul> <li>conservative</li> <li>good for cases where changes in predictor value have predictable effects on probability of predicted variable class</li> </ul> </li> <li>Interaction effect?</li> </ul> <p>logistic and step regression are good when interactions are not particularly common</p> <p><strong>Decision Trees</strong></p> <ul> <li>more cut out for interaction effect</li> <li>J 48 and C4.5 <ul> <li>can handle both numerical and categorical predictor variables</li> </ul> </li> <li>Pros: <ul> <li>relatively conservative due to pruning</li> </ul> </li> <li>good when <ul> <li>data has natural splits</li> <li>multi-level interactions are common</li> <li>same construct can be arrived in multiple ways</li> </ul> </li> </ul> <p> </p> <p> </p> <p> </p>; <p><strong><span style=""text-decoration: underline;"">1.4 Classifiers 2</span></strong></p> <p><strong>Decision Rules</strong></p> <ul> <li>if-then rules which you check in order</li> <li>JRip and PART</li> <li>Decision Tree</li> <li>if, if else, otherwise</li> <li>Pros: <ul> <li>relatively conservative</li> <li>unlike most other DM approaches</li> <li>good when multi-level interactions are common</li> </ul> </li> </ul> <p><strong>K*</strong></p> <ul> <li>predicts a data point from neighboring data points (weights points)</li> <li>good when <ul> <li>data is very divergent <ul> <li>intractable to find general rules</li> </ul> </li> </ul> </li> <li>Pros: <ul> <li>sometimes works when nothing else works</li> </ul> </li> <li>Cons: <ul> <li>to use the model, need to have whole data set</li> </ul> </li> </ul> <p><strong>Bagged Stumps<br /></strong></p> <ul> <li>Related to decision tree</li> <li>lots of trees with only first feature</li> <li>relatively conesrvative</li> <li><strong>random forest </strong>is a close variant (less conservative)</li> </ul> <p><strong>Common Thread</strong></p> <ul> <li>conservative <ul> <li>simple model, don't over fit</li> </ul> </li> </ul> <p><strong>Difficult Models/ Not too successful</strong></p> <p><strong>1) Support Vector Machines</strong></p> <ul> <li>Conducts demensionality reduction on data space and then fits hyperplane which splits classes</li> <li>creates sophisticated models</li> <li>good for <ul> <li>text mining</li> <li>sensor data</li> </ul> </li> <li>Not good for most of other educational data <ul> <li>logs, grades, interactions with software</li> </ul> </li> </ul> <p><strong>2) Genetic Algorithms</strong></p> <ul> <li>inconsistent answers</li> <li>mutation, combination, and natural selection to search space for possible models</li> </ul> <p><strong>3) Neural Networks</strong></p> <ul> <li><strong>perceptrons</strong> combined</li> <li>complicated models</li> <li>Soller &amp; Stevens (2007)</li> <li>difficulty of interpretation</li> </ul>; <p><span style=""text-decoration: underline;""><strong>2.2 Diagnostic Metrics Part 1</strong></span></p> <p>Metrics for Classifiers</p> <p>Accuracy</p> <ul> <li>= Agreement</li> <li>(number of agreements)/ (total number of codes/assessments)</li> <li>Not as good metrics <ul> <li>non-even assignment to categories</li> </ul> </li> </ul> <p>Kappa</p> <ul> <li>Cohen's Kappa</li> <li>(Agreement -Expected Agreement)/(1-Expected Agreement)</li> <li>Interpretation <ul> <li>0 <ul> <li>agreement is at chance</li> </ul> </li> <li>1 <ul> <li>agreement is perfect</li> </ul> </li> <li>-1 <ul> <li>agreement is perfectly inverse (opposite)</li> </ul> </li> <li>&gt;1 <ul> <li>messed up somewhere</li> </ul> </li> <li>&lt;0 <ul> <li>model is worse than chance</li> <li>very rare unless using cross-validation</li> </ul> </li> <li>0&lt;kappa&lt;1 <ul> <li>0.3-0.5 good enough</li> <li>lower is still often OK in affective computing</li> </ul> </li> </ul> </li> <li>Reason for no standard <ul> <li>kappa scaled by proportion of each cateogry</li> <li>harder to get kappa in imbalanced data</li> </ul> </li> <li>comparing kappa values between 2 data sets are different - OK to compare within a data set</li> </ul> <p> </p>; <p><span style=""text-decoration: underline;""><strong>2.3 Diagnostic Metrics Part 2</strong></span></p> <p>Classifiers</p> <p>Classifier goodness</p> <p>Receiver-Operating Characteristic Curve (ROC)</p> <ul> <li>predicting something that has two values</li> <li>prediction model outputs a probability or other real value</li> <li>Method: <ul> <li>take any number and use it as a cutoff</li> <li>0 or 1 if smaller or greater than threshold</li> </ul> </li> <li>4 possibilities <ul> <li>true positive</li> <li>false positive</li> <li>true negative</li> <li>false negative</li> </ul> </li> <li>ROC curve <ul> <li>X axis = percent false positives versus true negatives <ul> <li>false positives to the right, true negatives to the left</li> </ul> </li> <li>Y axis = percent true positives versus false negative <ul> <li>true positives go up, true negatives go down</li> </ul> </li> <li>dash line = chance <ul> <li>the more above dash line the better you are doing</li> </ul> </li> <li>above dash good</li> <li>stair steps good</li> <li>below dash so bad it is good</li> </ul> </li> </ul> <p>A'</p> <ul> <li>probability that if model is given an example from each category, it will accurately identify which is which</li> <li>Wilcoxon statistics</li> <li>not really a good way to compute A' for 3+ categories</li> <li>z test to compare two models A'</li> <li>Complication <ul> <li>assumes independence</li> </ul> </li> <li>closely mathematically approximates the area under the ROC curve called <strong>AUC</strong></li> </ul> <p>A' and Kappa</p> <ul> <li>A' <ul> <li>more difficult to compute</li> <li>almost always higher than kappa <ul> <li>because takes confidence into account</li> </ul> </li> </ul> </li> </ul> <p>Precision</p> <ul> <li>TP/ (TP+FP)</li> <li>the probability that the data point classified as true is actually true</li> </ul> <p>Recall</p> <ul> <li style=""text-align: left;"">TP/ (TP+FN)</li> <li style=""text-align: left;"">the probability that the data point that is actually true is classified as true</li> </ul> <p>limitation of precision and recall</p> <ul> <li>do not take confidence into account</li> </ul>; <p><span style=""text-decoration: underline;""><strong>2.4 Diagnostic Metrics: Correlation</strong></span></p> <p><em>https://www.youtube.com/watch?v=7r3hfJW1gz0&amp;feature=youtu.be</em></p> <p><span style=""text-decoration: underline;""><strong>Metrics for Regressors</strong></span></p> <p><strong>Linear Correlation</strong></p> <ul> <li>when A's value change, does B change direction</li> <li>assumes linear relationship</li> <li>correlation <ul> <li>good correlation <ul> <li>1 perfect</li> <li>0 non</li> <li>-1 perfectly negatively correlated</li> </ul> </li> <li>small correlation OK in education</li> <li>correlation vulnerable to outliers</li> </ul> </li> <li>r squared <ul> <li>correlation squared</li> <li>measure of goodness</li> </ul> </li> </ul> <p><strong>Root Mean Squared Error (RMSE)<br /></strong></p> <ul> <li>Mean absolute deviation <ul> <li>average of absolute value (actual value-predicted value)</li> </ul> </li> <li>RMSE <ul> <li>square root of average of (actual value-predicted value) squared</li> <li>large deviations</li> </ul> </li> </ul> <p>Good model</p> <ul> <li>Low RMSE/MAD is good</li> <li>high correlation is good</li> </ul> <p>Bad model</p> <ul> <li>high RMSE/MAD</li> <li>low correlation</li> <li>high RMSE/MAD and high correlation - Systematically biased model</li> <li>Low RMSE/MAD and low correlation - model values are in the right range, but model does not capture relative change</li> </ul> <p><strong>Information Criteria</strong></p> <ul> <li>Bayesian Information Criterion</li> <li>BIC' <ul> <li>over 0 = worse than expected given number of variables</li> <li>under 0 = better</li> </ul> </li> <li>BIC <ul> <li>statistically equivalent to k-fold cross validation for optimal k</li> </ul> </li> <li>AIC <ul> <li>alternative to BIC</li> </ul> </li> </ul> <p> </p>; <p><span style=""text-decoration: underline;""><strong>2.5 Cross-Validation and Over-Fitting</strong></span></p> <p><em><a href=""https://www.youtube.com/watch?v=1P34cxpEdKA&amp;feature=youtu.be"">https://www.youtube.com/watch?v=1P34cxpEdKA&amp;feature=youtu.be</a></em></p> <p>Overfitting</p> <ul> <li>fitting to noise as well as the signal</li> <li>Reduce overfitting <ul> <li>simpler models <ul> <li>fewer variables (BIC, AIC, Occam's Razor)</li> <li>less complex functions</li> </ul> </li> </ul> </li> <li>every model is over-fit in some fashion</li> <li>assessing generalizability <ul> <li>transferrable to new context?</li> <li>over-fit to a specific context?</li> </ul> </li> <li>Training set/test set</li> </ul> <p>Cross-validation</p> <ul> <li>split data points into n equal size groups</li> <li>train all groups but one test on last group</li> <li>for each possible combination</li> <li>How many groups? <ul> <li>k-fold <ul> <li>quicker</li> </ul> </li> <li>leave-out-one <ul> <li>more stable</li> </ul> </li> </ul> </li> <li>Variants <ul> <li>flat cross-validation <ul> <li>each point has equal chance of being placed into each fold</li> </ul> </li> <li>stratified cross validation <ul> <li>biases fold selection</li> </ul> </li> </ul> </li> <li>Student level cross-validation <ul> <li>test model generalization</li> <li>minimum cross-validation needed</li> </ul> </li> <li>Other levels <ul> <li>lesson</li> <li>school</li> <li>demographic</li> <li>software package</li> </ul> </li> <li>important consideration <ul> <li>where do you want to be able to use your model?</li> </ul> </li> </ul>; <p><span style=""text-decoration: underline;""><strong>4.2 Bayesian Knowledge Tracing</strong></span></p> <p><a href=""https://www.youtube.com/watch?v=_7CtthPZJ70&amp;feature=youtu.be"">https://www.youtube.com/watch?v=_7CtthPZJ70&amp;feature=youtu.be</a></p> <p><strong>Knowledge Inference: Bayesian Knowledge Tracing (BKT)</strong></p> <p><strong>BKT</strong></p> <ul> <li>classic approach for measuring tightly defined skill in online learning</li> <li>skills should be tightly defined</li> <li>typical use <ul> <li>assess a students knowledge of skill KC X</li> </ul> </li> <li>key assumptions <ul> <li>each item must involve single latent trait or skill</li> <li>each skill has four parameters</li> <li>two state learning models <ul> <li>each skill - learned or unlearned</li> </ul> </li> <li>problem solving, students can learn a skill at each opportunity to apply the skill</li> <li>student does not forget a skill</li> </ul> </li> <li>Model performance assumptions <ul> <li>slip - make mistake</li> <li>guess correctly</li> </ul> </li> </ul> <p><strong>Classical BKT</strong></p> <ul> <li>2 learning and 2 performance parameters</li> </ul> <p><strong>BKT</strong></p> <ul> <li>only uses first problem attempt on each item</li> </ul> <p><strong>Parameter Constraint</strong></p> <p><strong>model degeneracy</strong></p> <p><strong>Constraints proposed</strong></p> <p><strong>Knowledge Tracing</strong></p> <ul> <li>how well does model predicts performance</li> </ul> <p><strong>Fitting a knowledge tracing </strong></p> <p><strong>Fit methods</strong></p> <p> </p> <p> </p> <p> </p> <p> </p>; <p><span style=""text-decoration: underline;""><strong>7.1 Clustering</strong></span></p> <ul> <li>Structure discovery algorithm</li> <li>large number of data points - find structure among the data points</li> <li>don't know anything apriori about the structure</li> <li>ties to find data points to group them together</li> </ul> <p><strong>K-means clustering algorithms</strong></p> <ul> <li>simplest</li> </ul> <p><strong>Getting Clusters</strong></p> <ul> <li>decides number of clusters</li> <li>pick starting values for the ""centroids"" of the clusters <br /> <ul> <li>chosen randomly</li> </ul> </li> <li>classify every point as to which centroid it is close to <ul> <li>defines clusters</li> <li>visualized as: voronoi diagram</li> </ul> </li> <li>refit the centroids as the center of the points in each cluster</li> <li> <p>Note:</p> <ul> <li>outliers getting into cluster regardless</li> </ul> </li> </ul> <p>If the starting points are in strange places,</p> <ul> <li>run several times - involving several different starting points</li> </ul> <p> </p> <p> </p> <p> </p> <p> </p>; <p><span style=""text-decoration: underline;""><strong>7.2 </strong><strong>Validation and Selection of K</strong></span></p> <p><strong>Distortion = Mean Squared Deviation<br /></strong></p> <ul> <li>take each point P</li> <li>find the centroid of P's cluster C</li> <li>find the distance D from C to P</li> <li>square D to get D'</li> <li>sum all D' to get Distortion</li> </ul> <p><strong>Distance</strong></p> <ul> <li>Euclidean distance</li> </ul> <p><strong>Distortion works for choosing between randomized restarts, but does not work for choosing cluster size</strong></p> <ul> <li>More clusters almost always leads to smaller Distortion</li> <li>distance to the nearest cluster center should almost always be smaller with more clusters</li> </ul> <p><strong>Cross-validation cannot solve this problem</strong></p> <p><strong>Solution</strong></p> <ul> <li><strong> </strong>Penalize models with more clusters according to how much extra fit would be expected from the additional clusters</li> <li>Bayesian Info Criterion or Akaike Information Criteria</li> </ul> <p><strong>Using Information Criterion</strong></p> <ul> <li>assess how much fit would be spuriously expected from a random N centroids without allowing the centroids to move</li> <li>assess how much fit you actually had</li> <li>find the difference</li> </ul> <p><strong>So how many clusters?</strong></p> <ul> <li>Try several values of k</li> <li>find ""best-fitting"" set of clusters for each value of k</li> <li>choose k with best value of BiC or AIC</li> </ul> <p><strong>Alternate approach</strong></p> <p>Distance to nearest</p>; <p><span style=""text-decoration: underline;""><strong>7.6 Knowledge Inference - Q matrix</strong></span><strong></strong></p> <p><strong>Q-Matrix</strong></p> <ul> <li>Table</li> <li>rows = items</li> <li>columns = skills</li> <li>AKA: KC = Knowledge component model or Skill-item mapping</li> </ul> <p><strong>Methods to get Q-Matrix</strong></p> <ul> <li>Automatic model discovery</li> <li>Hand-development and refinements</li> <li>Hybrid approaches</li> </ul> <p><strong>Automatic model discovery (Barnes)<br /></strong></p> <ul> <li>Learn mapping between items and skills solely from data</li> <li>Empirically determine the number of skills</li> <li>Pseudocode <ul> <li>for each number of skills, the algorithm will run a certain number of times with a different, random, initial assignment of items to skills</li> <li>avoids local minima</li> </ul> </li> </ul> <p><strong>Better models?</strong></p> <ul> <li>performance on two items that involve the same skill should be connected</li> </ul> <p><strong>Subtlety</strong></p> <ul> <li>Is skill conjunctive?</li> <li>Compensatory?</li> </ul> <p><strong>Assumption</strong></p> <ul> <li>no learning</li> </ul> <p><strong>Hand Development and Refinement </strong></p> <ul> <li>try smooth learning curves <ul> <li>number of opportunities vs. error rate </li> </ul> </li> <li>look for skills with no apparent learning</li> <li>look for problems with unexpected error rates</li> </ul> <p> </p> <p> </p>","","","","","","","","","","","","","","","","","","","","","","","","1","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GXR866SX","videoRecording","2016","Georgia Tech","Cross Validation","","","","","https://www.youtube.com/watch?v=sFO2ff-gTh0","","2016-09-09","2019-09-17 21:41:56","2019-09-17 21:41:56","2016-09-09 19:37:11","","","","","","","","","","","","Youtube","","","","","","","","","","<p><span style=""text-decoration: underline;""><strong>Cross Validation</strong></span></p> <p>Train vs. Test</p> <p>Representative of how the system is ultimately going to be used</p> <p>Data being independent and identically distributed (IID)</p> <p>Fundamental assumption</p> <p>Use a model that is complex enough to fit the data without causing problem on the test set</p> <p>Training set that can act like test set: hold out some of the test set (pretend trial test set = cross validation set)</p> <p>To Pick a Model</p> <ol> <li>Take our training data and split them into folds</li> <li>Train on folds and check</li> <li>average all the errors (goodness of fit) to see how well we have done</li> <li>Pick lowest error</li> </ol>","","https://www.youtube.com/watch?v=sFO2ff-gTh0","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YKPFJ4KG","book","2019","Grolemund, Garrett","Hands-On Programming with R","","","","","https://rstudio-education.github.io/hopr/","This book will teach you how to program in R, with hands-on examples. I wrote it for non-programmers to provide a friendly introduction to the R language. You’ll learn how to load data, assemble and disassemble data objects, navigate R’s environment system, write your own functions, and use all of R’s programming tools. Throughout the book, you’ll use your newfound skills to solve practical data science problems.","2019-09-12","2019-09-17 21:41:56","2019-09-17 21:41:56","2019-09-12 17:12:28","","","","","","","","","","","","","","","","","","","rstudio-education.github.io","","","<p><span style=""text-decoration: underline;""><strong>Atomic Vectors: </strong></span></p> <p>- simple vector of a data</p> <p>- one-dimensional vector </p> <p>- each atomic vector can only store 2 type of data</p> <p>- types of atomic vectors: doubles, integers, characters, logicals, complex and raws</p> <p><span style=""text-decoration: underline;""><strong>Doubles</strong></span></p> <p>- stores regular numbers (positive, negative)</p> <p><span style=""text-decoration: underline;""><strong>Integers</strong></span></p> <p><strong>- </strong>R won’t save a number as an integer unless you include the L. Integer numbers without the L will be saved as doubles.</p> <p><span style=""text-decoration: underline;""><strong>Characters</strong></span></p> <p><strong>-</strong> create a character vector in R by typing a character or string of characters surrounded by quotes</p> <p><span style=""text-decoration: underline;""><strong>Logicals</strong></span></p> <p>-  TRUE and FALSE</p> <p><span style=""text-decoration: underline;""><strong>Complex and Raw </strong></span></p> <p>- complex: add an imaginary term to a number with i</p> <p>- Raw vectors store raw bytes of data</p> <p>- raw()</p> <p> </p> <p>attributes()</p> <p>names()</p> <p>dim()</p> <p> </p> <p><span style=""text-decoration: underline;""><strong>Matrices</strong></span></p> <p>- store values in a two-dimensional array</p> <p>- matrix will organize your vector of values into a matrix with the specified number of rows</p> <p>- m &lt;- matrix(die, nrow = 2, byrow = TRUE)</p> <p>- matrix will fill up the matrix column by column by default, but you can fill the matrix row by row if you include the argument byrow = TRUE</p> <p><span style=""text-decoration: underline;""><strong>Array</strong></span></p> <p>- ar &lt;- array(c(11:14, 21:24, 31:34), dim = c(2, 2, 3))</p> <div title=""Page 62""> <div> <div> <p>- array is not as customizeable as matrix and basically does the same thing as setting the dim attribute</p> <p><span style=""text-decoration: underline;""><strong>Class</strong></span></p> <p><span style=""text-decoration: underline;""><strong>Dates and Times</strong></span></p> <p>- Sys.time()</p> <p><span style=""text-decoration: underline;""><strong>Factor</strong></span></p> <p>- <span style=""font-size: 11.000000pt; font-family: 'MinionPro';"">way of storing categorical information </span></p> <p>- convert a factor to a character string with the as.character function</p> </div> </div> </div> <p><span style=""text-decoration: underline;""><strong>Coercion</strong></span></p> <p>- R always uses the same rules to coerce data to a single type: If character strings are present, everything will be coerced to a character string. Otherwise, logicals are coerced to numerics.</p> <p><span style=""text-decoration: underline;""><strong>List</strong></span></p> <div title=""Page 69""> <div> <div> <p>- list creates a list the same way c creates a vector</p> <p>- Groups data into 1-D set</p> <p><span style=""text-decoration: underline;""><strong>Data Frames</strong></span></p> <p>- two-dimensional version of a list</p> <p>- group vectors together into a two-dimensional table</p> <p> </p> <p><strong><span style=""text-decoration: underline;"">Loading Data</span></strong></p> <p><strong><span style=""text-decoration: underline;"">Saving Data</span></strong></p> <p>- save any data frame in R into a .csv file: write.csv(deck, file = ""cards.csv"", row.names = FALSE)</p> <p>- Where is my working directory: getwd()</p> <p> </p> <div class=""page"" title=""Page 78""> </div> </div> </div> </div>","","https://rstudio-education.github.io/hopr/","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SDC9CJ34","webpage","2019","Powell, V; Lehe, L","Principal Component Analysis explained visually","Explained Visually","","","","http://setosa.io/ev/principal-component-analysis/","","2019-09-12","2019-09-17 21:41:56","2019-09-17 21:41:56","2019-09-12 17:17:07","","","","","","","","","","","","","","","","","","","","","","<p><strong><span style=""text-decoration: underline;"">Principal Component Analysis - Explained Visually</span></strong></p> <p><strong>PCA</strong></p> <ul> <li>technique used to emphasize variation and bring out strong patterns in a data set</li> <li>makes data easy to explore and visualize</li> </ul> <p><strong>2D Example</strong></p> <ul> <li>PCA finds a new coordinate system in which every point has a new (x,y) value</li> <li>Axes <ul> <li>don't actually mean anything physical</li> <li>combinations of height and weight called ""principal components"" that are chosen to give one axes lots of variation</li> </ul> </li> </ul> <p><strong>3D Example</strong></p> <p><strong>17D Example</strong></p>","","http://setosa.io/ev/principal-component-analysis/","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""