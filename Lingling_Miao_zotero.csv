"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"383YUS4J","bookSection","2017","Bergner, Yoav","Measurement and its Uses in Learning Analytics","The Handbook of Learning Analytics","978-0-9952408-0-3","","","http://solaresearch.org/hla-17/hla17-chapter1","Psychological measurement is a process for making warranted claims about states of mind. As such, it typically comprises the following: de ning a construct; specifying a measurement model and (developing) a reliable instrument; analyzing and accounting for various sources of error (including operator error); and framing a valid argument for particular uses of the outcome. Measurement of latent variables is, after all, a noisy endeavor that can neverthe- less have high-stakes consequences for individuals and groups. This chapter is intended to serve as an introduction to educational and psychological measurement for practitioners in learning analytics and educational data mining. It is organized thematically rather than historically, from more conceptual material about constructs, instruments, and sources of measurement error toward increasing technical detail about particular measurement models and their uses. Some of the philosophical differences between explanatory and predictive modelling are explored toward the end.","2017","2019-09-17 21:46:15","2019-09-17 21:46:15","","34-48","","","","","","","","","","","Society for Learning Analytics Research (SoLAR)","Alberta, Canada","","","","","","","","","<p>two opinions for theory<br />Anderson: no longer do we need to create theories about how the world works.<br />Wise and Shaffer: theory is more important in interpreting results.(data archeology/data geology)</p> <p>educators and learners: data gathering, analysis, interpretation, and intervention is no longer the preserve of the research, but shifts to embedded sociotechnical educational infrastructure.</p> <p>ethical dilemmas:""wicked problems"" and complex adaptive systems.</p> <p>drive the new horsepower: to accelerate innovation and improve evidence-based decision-making.</p> <p>learning analytics are incarnation of an algorithmically pervaded society.</p> <p>assessment and pedagogy are built on the foundation of epistemology</p> <p>relationship: learning analytics support educational practices or challenge education education.</p> <p>Epistemology-what are we measuring: encourages us to consider our learning design, the skills and facts we want our students to learn.</p> <p>Epistemology-how are we measuring: assess to the knowledge.</p> <p>pedagogy-why is this knowledge important to us:debates around the kind of important knowledge and the role of knowledge-based curricula.</p> <p>pedagogy-who is assessment/analytic for: 1. individual students in developing their learning 2. educators in developing their own practice 3. administrators in understanding their organizational needs.<br />this question causes two concerns:1. create new divides between student cohorts 2. ethical concern regarding the use of student data.</p> <p>assessment-where does the assessment happen: in a physical location.</p> <p>assessment-when does the assessment, and feedback, occur: consideration of whether or not a particular technology provides after-the-fact or real-time feedback.</p> <p> </p>","","","","","Lang, Charles; Siemens, George; Wise, Alyssa Friend; Gaševic, Dragan","","","","","","","","","","","","","","","","","","","1","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IRKUSKEX","bookSection","2017","Prinsloo, Paul; Slade, Sharon","Ethics and Learning Analytics: Charting the (Un)Charted","The Handbook of Learning Analytics","978-0-9952408-0-3","","","http://solaresearch.org/hla-17/hla17-chapter1","As the field of learning analytics matures, and discourses surrounding the scope, de nition, challenges, and opportunities of learning analytics become more nuanced, there is bene t both in reviewing how far we have come in considering associated ethical issues and in looking ahead. This chapter provides an overview of how our own thinking has developed and maps our journey against broader developments in the  eld. Against a backdrop of technological advances and increasing concerns around pervasive surveillance and the role and unintended consequences of algorithms, the development of research in learning analytics as an ethical and moral practice provides a rich picture of fears and realities. More importantly, we begin to see ethics and privacy as crucial enablers within learning analytics. The chapter brie y locates ethics in learning analytics in the broader context of the forces shaping higher education and the roles of data and evidence before tracking our personal research journey, highlighting current work in the  eld, and concluding by mapping future issues for consideration.","2017","2019-09-17 21:46:15","2019-09-17 21:46:15","","49-57","","","","","","","","","","","Society for Learning Analytics Research (SoLAR)","Alberta, Canada","","","","","","","","","<p>Slade and Prinsloo estabilished one of the earliest framworks developed with a focus on ethics in learning analytics.</p> <p>why ethics is relevant: potential economic benefits resulting from increasing data harvesting. Ethical implications should take cognizance of the potentially conflicting interests and claims of a range of stakeholders.</p> <p>ethical issues: 1. the location and interpretation of data. 2. informed consent, privacy, and the de-identification of data. 3. the management, classification, and storage of data.</p> <p>Slade and Prinsloo proposed a framework based on six principles: 1. learning analytics are moreal practice 2. students as agents 3. student performance as temporal constructs 4. student success as a complex phenomenon. 5. transparency 6. the higher education cannot afford not to use data. ---supported by practical consideration</p> <p>recent developments in ethical frameworks: attempts in different geopolitical and institutional contexts. Welsh and Mckinney: relative immaturity of the discipline. Deachsler and Greller: broad overview of ethics, privacy, and frameworks, and challenges. Sclater: taxonomy of ethical, legal, and logistical. Engelfriet etal: protection of personal information. </p> <p>Future considerations: 1. conflicts between students' concerns, right to opt-out and institution use student information. 2. ethical research 3. concern balancing optimism around AI, machine learning and big data.</p> <p> </p>","","","","","Lang, Charles; Siemens, George; Wise, Alyssa Friend; Gaševic, Dragan","","","","","","","","","","","","","","","","","","","1","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4EHUPQRI","bookSection","2017","Brooks, Christopher; Thompson, Craig","Predictive Modelling in Teaching and Learning","The Handbook of Learning Analytics","978-0-9952408-0-3","","","http://solaresearch.org/hla-17/hla17-chapter1","This article describes the process, practice, and challenges of using predictive modelling in teaching and learning. In both the  elds of educational data mining (EDM) and learning analytics (LA) predictive modelling has become a core practice of researchers, largely with a focus on predicting student success as operationalized by academic achievement. In this chapter, we provide a general overview of considerations when using predictive modelling, the steps that an educational data scientist must consider when engaging in the process, and a brief overview of the most popular techniques in the  eld.","2017","2019-09-17 21:46:15","2019-09-17 21:46:15","","61-68","","","","","","","","","","","Society for Learning Analytics Research (SoLAR)","Alberta, Canada","","","","","","","","","<p>predictive analytics are a group of techniques used to make inferences about uncertain future events.</p> <p>Compare:<br />explanatory modelling: to use all available evidence to provide an explanation for a given outcome. Does not aim to make any claims about the future.A post-hoc and reflective activity aimed at generating an understanding of a phenomenon. All of the data collected from a sample is used to describe a population more genereally.<br />predictive modelling: to create a model that will predict the values of new data based on observations. Does aim to make claims about the futures. situ activity intended to make systems responsive to changes in the underlying data. Protect against the overfitting of models to data being used for training.</p> <p>4 types of data considered in statistical modelling: categorical, ordinal(categorical), interval(numeric), and ratio(numeric).</p> <p>missing values: 1. replace missing value with ""normal"" value 2. fill in missing values in records by finding other similar records in the dataset.</p> <p>Methods for building predictive models: 1. linear regression 2. logistic regression 3. nearest neighbours classifiers 4. decision tree 5. naive bayes classifiers 6. bayesian networks 7. support vector machines 8. neural networks 9. ensemble methods.</p>","","","","","Lang, Charles; Siemens, George; Wise, Alyssa Friend; Gaševic, Dragan","","","","","","","","","","","","","","","","","","","1","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZTXTACEC","bookSection","2017","Liu, Ren; Koedinger, Kenneth","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","The Handbook of Learning Analytics","978-0-9952408-0-3","","","http://solaresearch.org/hla-17/hla17-chapter1","In the statistical modelling of educational data, approaches vary depending on whether the goal is to build a predictive or an explanatory model. Predictive models aim to  nd a combination of features that best predict outcomes; they are typically assessed by their accuracy in predicting held-out data. Explanatory models seek to identify interpretable causal relationships between constructs that can be either observed or inferred from the data. The vast majority of educational data mining research has focused on achieving pre- dictive accuracy, but we argue that the  eld could bene t from more focus on developing explanatory models. We review examples of educational data mining efforts that have pro- duced explanatory models and led to improvements to learning outcomes and/or learning theory. We also summarize some of the common characteristics of explanatory models, such as having parameters that map to interpretable constructs, having fewer parameters overall, and involving human input early in the model development process.","2017","2019-09-17 21:46:15","2019-09-17 21:46:15","","69-76","","","","","","","","","","","Society for Learning Analytics Research (SoLAR)","Alberta, Canada","","","","","","","","","<p>two types of models: 1. statistical model 2. cognitive model</p> <p>statistical model:drive the outer loop of intelligent tutoring system based on observable features of students' performance as they learn.<br />cognitive model:representations of the knowledge space underlying a particular educational domain. it's a important basis for the instructional design and accurate assessment.</p> <p>method for cognitive model refinement iterates: 1. inspect curve visualization 2. identify KCs(knowledge component) 3. re-fit the AFM</p> <p>learning factors analysis automate the data-driven method of KC model refinement to further alleviate demands on human time. Different structure from the original dataset, it would not have been viable to apply directly the LFA-discovered KC mdoel on this new dataset.</p> <p>state-of-the-art machine-learning agent, SimStudent, to discover cognitive models. Benefit is can simulate features of novices' learning reajectories. SimStudent can be used to test alternative models of human learning to see which best predicts human behaviour.</p> <p>other model, ""human-in-the-loop"" component like Ordinal SPARFA-Tag yielded more interpretable cognitive models than many alternative methods.</p>","","","","","Lang, Charles; Siemens, George; Wise, Alyssa Friend; Gaševic, Dragan","","","","","","","","","","","","","","","","","","","1","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SN8HQFDP","journalArticle","2011","Gelman, A; Niemi, J","Statistical graphics: making information clear – and beautiful","Significance","","","","","","2011-09","2019-09-17 21:46:16","2019-09-17 21:46:16","","134-136","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"32Y4FSW9","journalArticle","2012","Gelman, A; Unwin, A","Infovis and Statistical Graphics: Different Goals, Different Looks (with discussion)","","","","","","","2012","2019-09-17 21:46:16","2019-09-17 21:46:16","","","","","","","","","","","","","","","","","","","","","","","<p>purpose of the present article is to start a conversation between practitioners in statistical graphics and information visualization.</p> <p>graphical communication of data and models are important part of statistical practice and theory.</p> <p>two group:1. statistical side, find effective ways of representing data, graphics enable readers to make up their own mind on any conclusion. 2. Infovis side, provide contextual information and try to tell a story</p> <p>goals for graphics:<br />Discovery goals: 1. giving a qualitative sense of dataset 2. conveying the sense of the scale and complexity of a dataset 3. flexible displays to discover unexpected aspects of the data.<br />Communication goals: 1. communication to self and others 2. telling a story 3. attracting attention and stimulating interest</p> <p>5 best data visualization projects of the year: 1. wordle 2. decision tree 3. radiohead music video 4. box office streamgraphs 5. britain from above</p> <p>problem of infographics: 1. plane crashes 2. Florence Nightingale's coxcomb: should prefer simple time-series plots 3. health spending and life expectancy: scatterplot more transparently and informatively 4. How to win in Afghanistan: no sense of priorities</p> <p>difference between statistical and infovis: 1. statistical prefer to use standard well-tried tools; infovis places high value on creativity 2. statisticians assume their viewers are already interested; infovis want to draw attention to their graphics, and as a door opener for the graphics</p> <p> </p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D4Z2ALHC","blogPost","2014","Fung, K","Junkcharts Trifecta Checkup: The Definitive Guide","Junkcharts","","","","http://junkcharts.typepad.com/junk_charts/junk-charts-trifecta-checkup-the-definitive-guide.html","","2014","2019-09-17 21:46:16","2019-09-17 21:46:16","","","","","","","","","","","","","","","","","Blog","","","","","","<p>Junk charts Trifecta Checkup: framework for data visualization criticism.</p> <p>Question: project needs a worthy cause.<br />Data: relevant to the question being addressed<br />Visual: represent the Data in a clear manner, addressing the question directly</p> <p>8 types of critiques:<br />1. the trifecta: everything is in sync, no weaknesses for chart<br />2. Type Q: poorly defined objective, or an unengaging premise make the effort fail.<br />3. Type D: the data fail to illuminate the question<br />4. Type V: the visual design confused the message<br />5. Type QD: poor data quality, and an unclear objective<br />6. Type QV: question not clearly defined and graphic design fail to bring out key features of the data.<br />7. Type DV: poor execution of the graphical elements and data fail to convince<br />8. Type QDV: graphical disasters do not get anything right</p> <p>when using the Trifecta Checkup Framework, question, data, visual are equally important.</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5NTEKRY8","journalArticle","2010","Bowers, Alex J.","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Practical Assessment, Research & Evaluation","","1531-7714","","","School personnel currently lack an effective method to pattern and visually interpret disaggregated achievement data collected on students as a means to help inform decision making. This study, through the examination of longitudinal K-12 teacher assigned grading histories for entire cohorts of students from a school district (n=188), demonstrates a novel application of hierarchical cluster analysis and pattern visualization in which all data points collected on every student in a cohort can be patterned, visualized and interpreted to aid in data driven decision making by teachers and administrators. Additionally, as a proof-of-concept study, overall schooling outcomes, such as student dropout or taking a college entrance exam, are identified from the data patterns and compared to past methods of dropout identification as one example of the usefulness of the method. Hierarchical cluster analysis correctly identified over 80% of the students who dropped out using the entire student grade history patterns from either K-12 or K-8. (Contains 5 figures.)","2010-05","2019-09-17 21:46:16","2019-09-17 21:46:16","2014-09-24 19:31:29","","","7","15","","","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students","","","","","","","en","","","","","ERIC","","","<p>Data driven decision making(3DM)</p> <p>teacher-a ssigned grades as useful data in schools: include academic knowledge, attendance, participation and behavior. 25% in grade is attributable to academic knowledge, 75% to assess a student's ability to negotiate the social processes of school.</p> <p>innovation in the data mining literature: 1. hierarchical cluster analysis(HCA), 2. heatmaps interpret longitudinal trends in student data.</p> <p>Method: 1. sample and district context  2. data collection 3. hierarchical cluster analysis: brings empirically defined organization to a set of previously unorganized data. two types of clustering: supervides and unsupervised. 4. missing data: reason: not all students take all of the same subjects; students dropped out of school before the end of grade 12, or transferred into or out of either district. 5. clustergrams: help visualize the organization and include a final set of data for each case's data row. 6. clustergram X-Axis subject order.</p> <p>Findings: 1. an example of hierarchical clustering: HCA using longitudinal grade histories. main goal of study is to present HCA and visualization techniques as a useful method for the organization and analysis to aid 3DM. 2. comparison to Past Dropout Identification Literature: goal is to identify students who will ultimately dropout of school</p>","","http://eric.ed.gov/?id=EJ933686","","data; data analysis; Decision Making; Dropouts; Elementary School Students; Grades (Scholastic); Identification; MULTIVARIATE analysis; School Districts; Secondary School Students","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZRYAA8D6","journalArticle","2014","Grunspan, Daniel Z.; Wiggins, Benjamin L.; Goodreau, Steven M.","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","CBE-Life Sciences Education","",", 1931-7913","10.1187/cbe.13-08-0162","http://www.lifescied.org/content/13/2/167","Social interactions between students are a major and underexplored part of undergraduate education. Understanding how learning relationships form in undergraduate classrooms, as well as the impacts these relationships have on learning outcomes, can inform educators in unique ways and improve educational reform. Social network analysis (SNA) provides the necessary tool kit for investigating questions involving relational data. We introduce basic concepts in SNA, along with methods for data collection, data processing, and data analysis, using a previously collected example study on an undergraduate biology classroom as a tutorial. We conduct descriptive analyses of the structure of the network of costudying relationships. We explore generative processes that create observed study networks between students and also test for an association between network position and success on exams. We also cover practical issues, such as the unique aspects of human subjects review for network studies. Our aims are to convince readers that using SNA in classroom environments allows rich and informative analyses to take place and to provide some initial tools for doing so, in the process inspiring future educational studies incorporating relational data.","2014-06-20","2019-09-17 21:46:16","2019-09-17 21:46:16","2014-08-20 20:21:46","167-178","","2","13","","CBE Life Sci Educ","Understanding Classrooms through Social Network Analysis","","","","","","","en","","","","","www.lifescied.org","","","<p>education researchers:study network formation within classrooms<br />three way to do analysis: 1. descriptive analysis of the network, 2. exploration of network evolution 3. analysis of network position as a predictor of individual outcomes.</p> <p>Social Network Basics: SNA help us understand how relationships form, what kinds of relational structures between pairs of actors, and the impacts are of these relationships on actors.</p> <p>Network Types: 1. number of types of actors they contain: one type of actor, student(unipartite); liking actors with the groups to which they belong(bipartite) 2. nature of the ties they contain: ties are inherently bidirectional(undirected); directed network. binary or valued.</p> <p>Network Data Collection: time frame of collection; how to sample from a population; census networks</p> <p>Network level concepts and Measures: network density(how many ties are present); who is connected with whom, homophily.</p> <p>data management: matrices are a powerful way to store and represent social network data.</p>","","http://www.lifescied.org/content/13/2/167","Week 2","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YEJ7NQN8","blogPost","2014","Young, Jeffrey R.","Why Students Should Own Their Educational Data","The Chronicle of Higher Education Blogs: Wired Campus","","","","http://chronicle.com/blogs/wiredcampus/why-students-should-own-their-educational-data/54329","","2014-08-21","2019-09-17 21:46:16","2019-09-17 21:46:16","2014-08-23 21:32:22","","","","","","","","","","","","","","","","","","","","","","<p>Everyone has different grade level. Even though they are in the same grade, they have different strengths and weakness. Now textbook or lecture is designed for average student, but actually there are no students are in average, most are higher or lower. This explained why there are lots of poor students, the reason for their bad grade is not because they are poor, there are no perfect customized textbook or lecture for them. Like some students are good at math, but poor at reading. Why they get the bad score in math, since reading requirement in the exam is higher than their level. Why students should own their educational data? Because individuals are in different level, not are in average. But all of textbooks are in average level. </p>","","http://chronicle.com/blogs/wiredcampus/why-students-should-own-their-educational-data/54329","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5MWCPL2G","journalArticle","1994","Corbett, Albert T.; Anderson, John R.","Knowledge tracing: Modeling the acquisition of procedural knowledge","User Modeling and User-Adapted Interaction","","0924-1868, 1573-1391","10.1007/BF01099821","http://link.springer.com.ezp-prod1.hul.harvard.edu/article/10.1007/BF01099821","This paper describes an effort to model students' changing knowledge state during skill acquisition. Students in this research are learning to write short programs with the ACT Programming Tutor (APT). APT is constructed around a production rule cognitive model of programming knowledge, called theideal student model. This model allows the tutor to solve exercises along with the student and provide assistance as necessary. As the student works, the tutor also maintains an estimate of the probability that the student has learned each of the rules in the ideal model, in a process calledknowledge tracing. The tutor presents an individualized sequence of exercises to the student based on these probability estimates until the student has ‘mastered’ each rule. The programming tutor, cognitive model and learning and performance assumptions are described. A series of studies is reviewed that examine the empirical validity of knowledge tracing and has led to modifications in the process. Currently the model is quite successful in predicting test performance. Further modifications in the modeling process are discussed that may improve performance levels.","1994-12-01","2019-09-17 21:46:17","2019-09-17 21:46:17","2013-04-21 21:21:19","253-278","","4","4","","User Model User-Adap Inter","Knowledge tracing","","","","","","","en","","","","","link.springer.com.ezp-prod1.hul.harvard.edu","","","<p>ACT programming tutor: practice envrionment in which student write short programs in Lisp, Prolog or Pascal. These three used by different school. <br />Three angle-bracket symbols in template:&lt;name&gt;/&lt;parameter&gt;/&lt;exprl&gt;</p> <p>Lisp: constructed around hundred rules for writing programs called the ideal student model. student's action is compared to applicable rules in the ideal model and immediate feedback is conventionally provided.</p> <p>The Cognitive Model: ACT-R theory: assumes a fundamental distinction between declarative knowledge(factual or experiential) and procedural knowledge(goal-oriented and mediated problem-solving behavior).</p> <p>Evaluating ACT-R procedural knowledge assumptions: three types to support:1. production rule model provides a regular analysis of learning trends. 2. production rule analyses have proven successful in predicting transfer among programming languages and across text editors. 3. a variety of results support the assumption that procedural knowledge is goal-specific. </p> <p>knowledge tracing: monitor the student's changing knowledge state during practice and ensure with a high probability that each rule is in the learned state. </p> <p>empirical evaluation of knowledge tracing: 1. general experimental procedure 2. internal validity: predicting tutor performance 3. external validity: predicting test performance 4. individual differences in learning and performance</p>","","","","Education (general); empirical validity; individual differences; intelligent tutoring systems; Learning; Management of Computing and Information Systems; mastery learning; Multimedia Information Systems; procedural knowledge; Psychology, general; student modeling; User Interfaces and Human Computer Interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8QN9H436","conferencePaper","2012","Siemens, George; Baker, Ryan S. J. d.","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Proceedings of the 2Nd International Conference on Learning Analytics and Knowledge","978-1-4503-1111-3","","10.1145/2330601.2330661","http://doi.acm.org/10.1145/2330601.2330661","Growing interest in data and analytics in education, teaching, and learning raises the priority for increased, high-quality research into the models, methods, technologies, and impact of analytics. Two research communities -- Educational Data Mining (EDM) and Learning Analytics and Knowledge (LAK) have developed separately to address this need. This paper argues for increased and formal communication and collaboration between these communities in order to share research, methods, and tools for data mining and analysis in the service of developing both LAK and EDM fields.","2012","2019-09-17 21:46:17","2019-09-17 21:46:17","2015-01-16 03:15:55","252–254","","","","","","Learning Analytics and Educational Data Mining","LAK '12","","","","ACM","New York, NY, USA","","","","","","ACM Digital Library","","","<p>Two distinct research communities: Educational Data Mining (EDM) and Learning Analytics and Knowledge (LAK).</p> <p>The first international conference: EDM - 2008; LAK -2010.</p> <p>Similarities between EDM and LAK: 1. he similar definition. 2. both reflect the emergence of data-intensive approaches to education. 3. both have the goal of improve the quality of analysis of data, to support research.</p> <p>Distinctions between EDM and LAK: 1. discovery 2. reduction&amp;holism 3. origins 4. adapation&amp;personalization 5. techniques&amp;methods</p>","","","","Collaboration; educational data mining; learning analytics and knowledge","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MNNN3BXW","book","2015","Zheng, Alice","Evaluating Machine Learning Models","","","","","http://www.oreilly.com/data/free/evaluating-machine-learning-models.csp?intcmp=il-data-free-lp-lgen_free_reports_page","Data science today is a lot like the Wild West: there’s endless opportunity and excitement, but also a lot of chaos and confusion. If you’re new to data science and applied machine learning, evaluating a machine-learning model can seem pretty overwhelming...","2015-09","2019-09-17 21:46:17","2019-09-17 21:46:17","2015-12-15 18:26:39","","","","","","","","","","","","O'Reily Media","Sebastopol, CA","","","","","","","","","<p>classification is about predicting class labels given input data.</p> <p>accuracy = # correct predictions / # total data points<br />a variation of accuracy is the average per-class accuracy- the average of the accuracy for each class. </p> <p>AUC stands for area under the curve. AUC is one way to summarized the ROC curve into a single number. ROC curve shows the sensitivity of the classifier by plotting the rate of true positives to the rate of false positives.</p> <p>Precision-recall: two metrics, but used together.They answer the different questions. precision: #happy correct answers/#total items returned by ranker. recall: #happy correct answers/#total relevant items.<br />F1 = 2(precision*recall/(precision+recall))</p> <p>NDCG: normalized discounted cumulative gain. cumulative gain(CG); discounted cumulative gain(DCG).<br />regression metrics: learn to predict numeric scores. most commonly used metric is RMSE(root-mean-square-error).Since RMSE is an average, its sentitive to large ourliers. Quantiles are much more robust. MAPE(median absolute percentage).</p> <p>The difference between training metrics and evaluation metrics: training model always better to directly optimize for the metric it will be evaluated on.</p> <p>skewed datasets- imbalanced classes, outliers, and rare data: always be on the look out for data skew. Good classifier should have accuracy much high than 99%. Metric that gives equal weight to each instance of a class has a hard time handling imbalanced classes. The resulting model may not know how to predict the rare classes if class imbalance is not properly dealt with. Another problem is outliers. large outliers can be mitigated during evaluation but not for the training phase. The solution for it is doing careful data cleaning and reformulating the task.</p>","","http://www.oreilly.com/data/free/evaluating-machine-learning-models.csp?intcmp=il-data-free-lp-lgen_free_reports_page","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z4B5RWP9","blogPost","2015","Leong, B; Polonetsky, J","Why Opting Out of Student Data Collection Isn’t the Solution","EdSurge","","","","https://www.edsurge.com/news/2015-03-16-why-opting-out-of-student-data-collection-isn-t-the-solution","In every privacy debate across every industry, the same questions arise about the rights of individuals to “opt-out” of their data being collected or used. So it should come as no surprise that the “when” and “how” of parent and student opt-outs of education data collection or use has become a robust","2015-03-16","2019-09-17 21:46:17","2019-09-17 21:46:17","2016-01-16 16:31:25","","","","","","","","","","","","","","","","","","","","","","","","https://www.edsurge.com/news/2015-03-16-why-opting-out-of-student-data-collection-isn-t-the-solution","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3KK32DIR","videoRecording","2015","Educause","Why Is Measuring Learning So Difficult?","","","","","https://www.youtube.com/watch?v=_iv8A1pHNYA","Several higher education learning and assessment professionals discuss the difficulties of measuring learning.","2015-08-17","2019-09-17 21:46:17","2019-09-17 21:46:17","2016-01-17 18:50:57","","","","","","","","","","","","","","","","","","","YouTube","","","","","","","Learning; Assessment; Education; educational assessment; EDUCAUSE; Higher Education; learners; Teaching and learning","","","","","","","","","","","","","","","","","","","","","470 seconds","","","","","","","","","","","","","","","","","","","","","","","","",""
"SZG9UNAW","webpage","2016","Weinersmith, Zach","Saturday Morning Breakfast Cereal","","","","","http://www.smbc-comics.com/index.php?id=3978","","2016-01-05","2019-09-17 21:46:17","2019-09-17 21:46:17","2016-01-18 18:17:09","","","","","","","","","","","","","","","","","","","","","","<p>90% of elite engineers were interested to reassemble clocks as children, but it does not mean all children who start reassemble clocks will be elite engineers. In the education, interests are the most important. If children like doing something, they will accept those knowledge faster. Otherwise, even though school has the course to force children to learn, they still refused to learn and have a hard time to get the achievement in the field.</p> <p>Thus, interests will promote children to be elite in the specific field. “we clocked so much clock that we're off the clock"". Children like clock, when forcing them to do, they will refuse to work and even stop doing relative thing at the end.</p>","","http://www.smbc-comics.com/index.php?id=3978","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WZNB2THR","conferencePaper","2014","Clow, Doug","Data wranglers: human interpreters to help close the feedback loop","Proceedings of the Fourth International Conference on Learning Analytics And Knowledge","","","","","","2014","2019-09-17 21:46:18","2019-09-17 21:46:18","","49–53","","","","","","","","","","","ACM","","","","","","","","","","<p>Data Wranglers: group of academics who analyse data about student learning and prepare reports with actionable recommendations based on that data. The role is not only to anaylse the data, but  to increase the familiarity of academics with the data sources, to building learning analytics capacity.</p> <p>Role: 1. act as human sense-makers 2. facilitating action on feedback from learners 3. making better sense of what that feedback means and how the data can be improved 4. helping to develop the Community of Practice around the use of learning analytics.</p> <p>Results: Tools using like SAS data warehouse to aggregated data sources and Tableau to export. Data wranglers use workbooks as their primary data to generate some charts and visualisations. Also use the data directly to produce their own charts in Excel.</p> <p>Macfadyen &amp; Dawson's analysis of LMS - technical discussions    <br />Data Wrangler - analytic processes</p> <p> </p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IM96H89Z","magazineArticle","2015","Kucirkova, Natalia; FitzGerald, Elizabeth","Zuckerberg is ploughing billions into 'personalised learning' – why?","The Conversation","","","","http://theconversation.com/zuckerberg-is-ploughing-billions-into-personalised-learning-why-51940","Zuckerburg wants to plough billions into personalised learning, but his way may not be the right way.","2015-12-09","2019-09-17 21:46:18","2019-09-17 21:46:18","2016-01-18 19:14:05","","","","","","","","","","","","","","","","","","","","","","<p>There is no clear definition for personalised learning now but I agree with the definition from Zuckerberg,""working with students to customise instruction to meet the student's individual needs and interests"". In my opinions, since every student has different level, they need special material for them, like some students are good at math rather than verbal, they might need high level of math material and middle level of verbal.</p> <p>Dangers of personalised learning: 1. we will get many specialists and few generalists. 2. learners will lost their ability of compensations. 3. students, teachers and parents will lose social contact between each other. 4. data is easy to lose and misused. </p> <p>nobody can guarantee personalised learning will be success. And even though you are rich enough, doing personalised learning is still hard, since it not only related with the technology problem, but also related the conversation and collaboration, how to balance the technology and teachers.</p>","","https://theconversation.com/zuckerberg-is-ploughing-billions-into-personalised-learning-why-51940","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6AWUV8E9","videoRecording","2015","Georgia Tech","Feature Selection","","","","","https://www.youtube.com/watch?v=8CpRLplmdqE","","2015-02-23","2019-09-17 21:46:18","2019-09-17 21:46:18","2016-01-18 19:18:06","","","","","","","","","","","","Youtube","","","","","","","","","","<p>Feature Selection<br />1. knowledge discovery interpretabicity &amp; insight (humanbeing)<br />    useful when thinking about a set of data in a problem, to be able to interpret the features. <br />2. curse of dimensionality(machine learning): the amount of data that you need grows exponentially in the number of features that you have.</p> <p>selection: from whole bunch of features to a few features. use algorithm to get just important features. help to understand data better and have easier learning problem.</p>","","https://www.youtube.com/watch?v=8CpRLplmdqE","","","","","","","","","","","","","","","","","","","","","","","3:13","","","","","","","","","","","","","","","","","","","","","","","","",""
"PTUQK2QM","bookSection","2016","Hanneman, R.A.; Riddle, M.","Chapter 1: Social Network Data","Introduction to Social Network Methods","","","","http://faculty.ucr.edu/~hanneman/nettext/C1_Social_Network_Data.html","","2016-01-18","2019-09-17 21:46:18","2019-09-17 21:46:18","2016-01-18 20:17:24","","","","","","","","","","","","","","","","","","","","","","<p>difference between conventional and network data: conventional data focuses on actors and attributes; network data focus on actors and relations</p> <p>network analysis: 1. seeing how actors are located in the overall network<br />2. seeing how the whole pattern of individual choices gives rise to more holistic patterns</p> <p>boundaries of the populations: 1. boundaries are created by the actors themselves. 2. more demographic or ecological approach</p> <p>strategies for deciding how to collecting  measurements on the realations among them: 1. full network methods: yields the maximum of informaiton 2. snowball methods: giving some thought to how to select the initial nodes. weakness: 1. actors who are not connected are not located 2. no guaranteed way of finding all of the connected individuals.</p> <p>ego-centric networks with alter connections: the network as a whole<br />ego-centric networks ego only: focus on the individual</p> <p>multiple relations: 1.scales of measurement 2. binary measures of relations 3. multiple-category nominal measures of relations 4. grouped ordinal measures of relations 5. full-rank ordinal measures of relations 6. interval measures of relations</p> <p>mathematical approach: treat the data as ""deterministic""<br />statistical analysts: regard the scores on relationship as probabilistic realizations</p>","","http://faculty.ucr.edu/~hanneman/nettext/C1_Social_Network_Data.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G4ET6NDH","webpage","2014","Groelmund, Garrett","RStudio Cheat Sheets","RStudio","","","","https://www.rstudio.com/resources/cheatsheets/","","2014-08-01","2019-09-17 21:46:18","2019-09-17 21:46:18","2016-01-19 21:17:28","","","","","","","","","","","","","","","","","","","","","","<p>Data Wrangling<br />1.%&gt;% passed object on left hand side as first argument of function on righthand side.<br />2. gather(cases, ""year"", ""n"", 2:4): gather columns into rows.<br />3. spread(pollution, size, amount): spread rows into columns.<br />4. separate(storms, date, c(""y"", ""m"", ""d"")): separate one column into several<br />5. unite(data, col, ..., sep): unite several columns into one.<br />6. data_frame(a = 1:3, b = 4:6)<br />7. arrange(mtcars, mpg): order rows by values of a column(low to high)<br />8. arrange(mtcars, desc(mpg)): order rows by values of a column (high to low)<br />9. rename(tb, y = year): rename the columns of a data frame.<br />10. filter(iris, Sepal.Length &gt;7): extract rows that meet logical criteria<br />11. distinct(iris): remove duplicate rows.<br />12. slice(iris, 10:15): select rows by position<br />13. select(iris, Sepal.Width, Petal.Length, Species): select columns by name or helper function(contains(), ends_with(), everything(),matches(), starts_with()).<br />14. summarise(iris, avg = mean(Sepal. Length)): summarise data into single row of values<br />15. summarise_each(iris, funs(mean)): apply summary function to each column.<br />16. group_by(iris, Species): group data into rows with the same value of Species.<br />17. mutate(iris, sepal = Sepal.Length + Sepal. Width): compute and append one or more new columns<br />18. left_join(a,b,by = ""x1"")//right_join, inner_join, full_join, semi_join, anti_join.<br />19. intersect(y,z): rows that appear in both y and z<br />20. union(y,z): rows that appear in either or both y and z<br />21. setdiff(y,z): rows that appear in y but not z<br />22. bind_rows(y,z)///bind_cols(y,z)</p> <p> </p> <p> </p>","","http://shiny.rstudio.com/articles/rm-cheatsheet.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4R7WXK79","conferencePaper","2013","san Pedro, Maria Ofelia; Baker, Ryan; Bowers, Alex; Heffernan, Neil","Predicting college enrollment from student interaction with an intelligent tutoring system in middle school","Educational Data Mining 2013","","","","","","2013","2019-09-17 21:46:18","2019-09-17 21:46:18","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9AX5APR9","journalArticle","2012","Greller, Wolfgang; Drachsler, Hendrik","Translating Learning into Numbers: A Generic Framework for Learning Analytics","Journal of Educational Technology & Society","","1176-3647","","http://www.jstor.org/stable/jeductechsoci.15.3.42","ABSTRACT With the increase in available educational data, it is expected that Learning Analytics will become a powerful means to inform and support learners, teachers and their institutions in better understanding and predicting personal learning needs and performance. However, the processes and requirements behind the beneficial application of Learning and Knowledge Analytics as well as the consequences for learning and teaching are still far from being understood. In this paper, we explore the key dimensions of Learning Analytics (LA), the critical problem zones, and some potential dangers to the beneficial exploitation of educational data. We propose and discuss a generic design framework that can act as a useful guide for setting up Learning Analytics services in support of educational practice and learner guidance, in quality assurance, curriculum development, and in improving teacher effectiveness and efficiency. Furthermore, the presented article intends to inform about soft barriers and limitations of Learning Analytics. We identify the required skills and competences that make meaningful use of Learning Analytics data possible to overcome gaps in interpretation literacy among educational stakeholders. We also discuss privacy and ethical issues and suggest ways in which these issues can be addressed through policy guidelines and best practice examples.","2012","2019-09-17 21:46:19","2019-09-17 21:46:19","2016-09-03 18:55:41","42-57","","3","15","","Journal of Educational Technology & Society","Translating Learning into Numbers","","","","","","","","","","","","JSTOR","","","<p>critical dimensions:<br />1. hard issues: challenges of the fact-based world of data and algorithms. example: compatibility of educational datasets, the comparability and adequacy of algorithmic and technological approaches.<br />2. soft issues: challenges that depend on assumptions being made about humans or the society in general. example: questions of data ownership and oppenness, ethical use and dangers of abuse, ad the demand for new key competences to interpret and act.</p> <p>design framework: framework intends to be a guide as much as a descriptor of the problem zones.</p> <p>dimension of LA framework: <br />(1)stakeholders: data clients: terachers; data subjects (learners)<br />(2)objectives: reflection:self-evaluation; prediction: predicting and modelling learner activities.<br />(3)data:protected dataset; relevant indicators; time scale<br />(4instruments: pedagogic theory; technology; presentation<br />(5)external constraints: conventions: privacy, ethics; time scale; norms<br />(6)internal limitations: competences and acceptance</p> <p>six dimensions are mandatory to be present in LA design. The interests of the learners is important for the development of LA. Development should not happen without a guiding framework(use of educational data and protection of individuals)</p> <p>question in LA: the relation with theories of learning, teaching, cognition and knowledge.</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VZFN3RCI","bookSection","2006","Kay, Judy; Maisonneuve, Nicolas; Yacef, Kalina; Reimann, Peter","The Big Five and Visualisations of Team Work Activity","Intelligent Tutoring Systems","978-3-540-35159-7 978-3-540-35160-3","","","http://link.springer.com/chapter/10.1007/11774303_20","We have created a set of novel visualisations of group activity: they mirror activity of individuals and their interactions, based upon readily available authentic data. We evaluated these visualisations in the context of a semester long software development project course. We give a theoretical analysis of the design of our visualizations using the framework from the “Big 5” theory of team work as well as a qualitative study of the visualisations and the students’ reflective reports. We conclude that these visualisations provide a powerful and valuable mirroring role with potential, when well used, to help groups learn to improve their effectiveness.","2006-06-26","2019-09-17 21:46:19","2019-09-17 21:46:19","2016-09-03 19:10:12","197-206","","","","","","","Lecture Notes in Computer Science","4053","","","Springer Berlin Heidelberg","","en","©2006 Springer-Verlag Berlin Heidelberg","","","","link.springer.com","","DOI: 10.1007/11774303_20","","","https://link.springer.com/chapter/10.1007/11774303_20","","Multimedia Information Systems; User Interfaces and Human Computer Interaction; Artificial Intelligence (incl. Robotics); Computers and Education; Information Systems Applications (incl. Internet)","Ikeda, Mitsuru; Ashley, Kevin D.; Chan, Tak-Wai","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HQ6Y4N5C","journalArticle","2015","Konstan, Joseph A.; Walker, J. D.; Brooks, D. Christopher; Brown, Keith; Ekstrand, Michael D.","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","ACM Trans. Comput.-Hum. Interact.","","1073-0516","10.1145/2728171","http://doi.acm.org/10.1145/2728171","","2015-04","2019-09-17 21:46:19","2019-09-17 21:46:19","2016-09-03 20:38:02","10:1–10:23","","2","22","","","Teaching Recommender Systems at Large Scale","","","","","","","","","","","","ACM Digital Library","","","<p>trial MOOCS: 1. we did not choose new material and we adjust design to reflect MOOC delivery to both world and students.2. developing the software platform which students could carry out many of the activities 3. accessible to nonprogrammers as well as programmers.</p> <p>Research Methods: 1. design: single-group cross-sectional research design. 2. participants 3. measures: use pre- and postclass surveys designed to measure students' background. 4. preliminary analyses: by examming a set of questions that asked students to rate.</p> <p>Difficult to study the differences in learning between face to face and MOOC due to the lack of a measure of baseline understanding or knowledge.</p> <p>Results: students knowledge increased; limited data suggests that face-to-face students learned at least as much as online-only students; students at all incoming knowledge levels benefited similarly from the course; students in the programming and concepts tracks had similar gains in concepts knowledge, but programming students gained further knowledge. Normalized knowledge gains are very difficult to predict; measures of relevant effort were strongest; predicting student end-of-term performance is difficult; appropriate predictor variables may be lacking.</p>","","","","learning assessment; Massively Online Open Course (MOOC)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T2KNHX5K","bookSection","2013","Desmarais, Michel C.; Naceur, Rhouma","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","Artificial Intelligence in Education","978-3-642-39111-8 978-3-642-39112-5","","","http://link.springer.com/chapter/10.1007/978-3-642-39112-5_45","Uncovering the right skills behind question items is a difficult task. It requires a thorough understanding of the subject matter and of the cognitive factors that determine student performance. The skills definition, and the mapping of item to skills, require the involvement of experts. We investigate means to assist experts for this task by using a data driven, matrix factorization approach. The two mappings of items to skills, the expert on one side and the matrix factorization on the other, are compared in terms of discrepancies, and in terms of their performance when used in a linear model of skills assessment and item outcome prediction. Visual analysis shows a relatively similar pattern between the expert and the factorized mappings, although differences arise. The prediction comparison shows the factorization approach performs slightly better than the original expert Q-matrix, giving supporting evidence to the belief that the factorization mapping is valid. Implications for the use of the factorization to design better item to skills mapping are discussed.","2013-07-09","2019-09-17 21:46:19","2019-09-17 21:46:19","2016-09-03 20:44:11","441-450","","","","","","","Lecture Notes in Computer Science","7926","","","Springer Berlin Heidelberg","","en","©2013 Springer-Verlag Berlin Heidelberg","","","","link.springer.com","","DOI: 10.1007/978-3-642-39112-5_45","","","https://link.springer.com/chapter/10.1007/978-3-642-39112-5_45","","User Interfaces and Human Computer Interaction; Artificial Intelligence (incl. Robotics); Computers and Education; Information Systems Applications (incl. Internet); alternating least squares matrix factorization; Cognitive modeling; Educational Technology; latent skills; Pedagogic Psychology; skills assessment; Student models","Lane, H. Chad; Yacef, Kalina; Mostow, Jack; Pavlik, Philip","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BQ2AT4IU","book","2015","Matsuda, Noboru; Furukawa, Tadanobu; Bier, Norman; Faloutsos, Christos","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","","","","","http://eric.ed.gov/?id=ED560513","How can we automatically determine which skills must be mastered for the successful completion of an online course? Large-scale online courses (e.g., MOOCs) often contain a broad range of contents frequently intended to be a semester's worth of materials; this breadth often makes it difficult to articulate an accurate set of skills and knowledge (i.e., a skill model, or the QMatrix). We have developed an innovative method to discover skill models from the data of online courses. Our method assumes that online courses have a pre-defined skill map for which skills are associated with formative assessment items embedded throughout the online course. Our method carefully exploits correlations between various parts of student performance, as well as in the text of assessment items, to build a superior statistical model that even outperforms human experts. To evaluate our method, we compare our method with existing methods (LFA) and human engineered skill models on three Open Learning Initiative (OLI) courses at Carnegie Mellon University. The results show that (1) our method outperforms human-engineered skill models, (2) skill models discovered by our method are interpretable, and (3) our method is remarkably faster than existing methods. These results suggest that our method provides a significant contribution to the evidence-based, iterative refinement of online courses with a promising scalability. [For complete proceedings, see ED560503.]","2015-06","2019-09-17 21:46:20","2019-09-17 21:46:20","2016-09-03 20:48:57","","","","","","","Machine Beats Experts","","","","","International Educational Data Mining Society","","en","","","","","ERIC","","","<p>eEPIPHANY: a collection of data-mining techniques to automatically refine a human-crafted set of skills, it is efficient, practical and scalable method. Its goal is provide constructive feedback to online course designers and developers for iterative course improvement.</p> <p>Contributions: 1. new problem formulation 2. new algorithm 3. evaluation</p> <p>Skill-item association: mapping between a single skill and multiple assessment items in the skill map.</p> <p>steps for eEPIPHANY: 1. clustering assessment item 2. proposing a new skill model 3. searching for the best skill model</p> <p>two latent-feature extraction strategies: 1. the Matrix Factorization(MF): transformed A-matrix into the D-matrix 2. the Bag-of-Words(BoW): creates the F-matrix directly from a collection of item stems</p> <p>Feature extraction is to generate a two-dimensional matrix, showing a mapping betwen assessment items and skill candidates.</p> <p>three strategies to refine the ""default"" skill model: 1. replace strategy 2. append strategy 3. split strategy</p> <p> </p>","","http://eric.ed.gov/?id=ED560513","","data; Automation; Comparative Analysis; Correlation; Formative Evaluation; models; Online Courses; Skills","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KU92L2CU","conferencePaper","2008","Cortez, Paulo; Silva, Alice Maria Gonçalves","Using data mining to predict secondary school student performance","Proceedings of 5th Annual Future Business Technology Conference","978-90-77381-39-7","","","http://repositorium.sdum.uminho.pt/handle/1822/8024","Although the educational level of the Portuguese population has improved in the last decades, the statistics keep Portugal at Europe’s tail end due to its high student failure rates. In particular, lack of success in the core classes of Mathematics and the Portuguese language is extremely serious. On the other hand, the fields of Business Intelligence (BI)/Data Mining (DM), which aim at extracting high-level knowledge from raw data, offer interesting automated tools that can aid the education domain. The present work intends to approach student achievement in secondary education using BI/DM techniques. Recent real-world data (e.g. student grades, demographic, social and school related features) was collected by using school reports and questionnaires. The two core classes (i.e. Mathematics and Portuguese) were modeled under binary/five-level classification and regression tasks. Also, four DM models (i.e. Decision Trees, Random Forest, Neural Networks and Support Vector Machines) and three input selections (e.g. with and without previous grades) were tested. The results show that a good predictive accuracy can be achieved, provided that the first and/or second school period grades are available. Although student achievement is highly influenced by past evaluations, an explanatory analysis has shown that there are also other relevant features (e.g. number of absences, parent’s job and education, alcohol consumption). As a direct outcome of this research, more efficient student prediction tools can be be developed, improving the quality of education and enhancing school resource management.","2008-04","2019-09-17 21:46:20","2019-09-17 21:46:20","2016-09-04 01:23:19","","","","","","","","","","","","EUROSIS","Porto, Spain","eng","openAccess","","","","repositorium.sdum.uminho.pt","","","","","http://repositorium.sdum.uminho.pt/handle/1822/8024","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","5th Annual Future Business Technology Conference","","","","","","","","","","","","","","",""
"SGGNXC8Q","journalArticle","2008","Baker, Ryan S. J. d; Corbett, Albert T.; Roll, Ido; Koedinger, Kenneth R.","Developing a generalizable detector of when students game the system","User Modeling and User-Adapted Interaction","","0924-1868, 1573-1391","10.1007/s11257-007-9045-6","http://link.springer.com/article/10.1007/s11257-007-9045-6","Some students, when working in interactive learning environments, attempt to “game the system”, attempting to succeed in the environment by exploiting properties of the system rather than by learning the material and trying to use that knowledge to answer correctly. In this paper, we present a system that can accurately detect whether a student is gaming the system, within a Cognitive Tutor mathematics curricula. Our detector also distinguishes between two distinct types of gaming which are associated with different learning outcomes. We explore this detector’s generalizability, and find that it transfers successfully to both new students and new tutor lessons.","2008-01-23","2019-09-17 21:46:20","2019-09-17 21:46:20","2016-09-04 01:34:49","287-314","","3","18","","User Model User-Adap Inter","","","","","","","","en","","","","","link.springer.com","","","","","https://link.springer.com/article/10.1007/s11257-007-9045-6","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QBGUKXHJ","book","2014","Baker, R","Big Data in Education","","","","","","","2014","2019-09-17 21:46:20","2019-09-17 21:46:20","","","","","","","","","","","","","","New York, NY","","","","","","","","","<p>Video 1 chapter 7</p> <p>Clustering: a type of structure discovery algorithm<br />1. you have a large number of data points<br />2. you want to find what structure there is among the data points<br />3. you do not know anything a priori about the structure<br />4. clustering tries to find data points that""group together""</p> <p>k-means steps:<br />how many clustering we want:orange, green, red, purple, black(different color point)<br />centroids: usually chosen randomly<br />classify every point <br />re-fit the centroids as the center of the points in the each cluster<br />convergence<br />some outliers are exist</p> <p>Video 2 chapter 7</p> <p>clustering: validation and selection of k</p> <p>distortion: mean squared deviation, can not choose size of k<br />1. take each point p<br />2. find the centroidof P's cluster C<br />3. find the distance D from C to P<br />4. square D to get D'<br />5. sum all D' to get distortion<br />Distance: euclidean  distance can be computed an arbitrary number of dimension</p> <p>information criterion:<br />1. assess how much fit would be expected from a random N centroids<br />2. assess how much fit you actually had<br />3. find the difference</p> <p>how many clusters:<br />1. try several values of k<br />2. find “best-fitting” set of clusters for each value of k<br />3. choose k with best value of BIC/AIC</p> <p>Video 6 chapter 7</p> <p>Q-matrix: a table where rows are items and columns are skills. It is also called knowledge component (KC) model or skill-item mapping.<br />Every item must include at least one skill.</p> <p>How do we get a skill-item mappting:<br />1. automatic model discovery: learn the mapping between items and skills solely from data.<br />Barnes et al.'s: better model property: 1. given a skill-item mapping, you can predict for each combination of skills whether a student should get each item correct or not. 2. fit a model like PFA or BKT, and see how well it fits data, given the skill-item mapping. <br />2. hand-development and refinement: original way that Q-matrices were created actually. strategies for Q-matrix refinement: 1). try to smooth learning curves(shows relationship between amount of practice and performance) 2). look for skills with no apparent learning 3). look for problems with unexpected error rates:DataShop<br />3. hybrid approaches</p> <p>Video 1 Chapter 1</p> <p>joint goal of exploring and promote<br />types of EDM/LA method: 1. prediction: develop a model infer a single aspect data 2. structure discovery: find structure and patterns in the data, no specific target 3. relationship mining: find relationship between variables in a data set with many variables 4. distillation of data for human judgement 5. discovery with models</p> <p>why data mining did not start more earlier: no enough data and hard to scale</p> <p>Video 3 Chapter 1</p> <p>classification: the thing you want to predict is categorical, to determine which features in which combination can predict the label. <br />labels come from: in-software performance/school records/test data/survey data/field observation or video coding/text replays.<br />step regression: fit linear regression function, all value below 0.5 are treated as 0 and all value &gt;=0.5 are treated as 1. <br />logistic regression: fits logistic function to data to find out the frequency, closer to 1. <br />decision trees</p> <p>Video 4 Chapter 1</p> <p>decision rule: sets of if-then rules which you check in order<br />K*: predicts a data point from neighboring data points, good when data is very divergent. advantage is works when nothing else works. Drawback is need to have the whole data set. <br />Bagged Stumps: related to decision trees, relatively conservative.<br />support vector machine/genetic algorithms/neural networks(complicated model) good for some problem but not for most type of educational data.</p> <p>Video 2 Chapter 2</p> <p>Diagnostic matrics: different methods, different matrics.</p> <p>accuracy: easiest measures of model goodness, # of agreements/total number of codes/assessments.</p> <p>Kappa: (agreement-expected agreement)/(1-expected agreement)<br />Kappa = 0, agreement is at chance<br />Kappa = 1, agreement is perfect<br />Kappa = -1, agreement is perfectly inverse<br />Kappa &gt;1, you messed up somewhere<br />Kappa &lt;0, model is worse than chance, very rare unless using cross-validation.<br />0&lt;Kappa &lt;1, typically 0.3-0.5 is good.<br />Kappa is scaled by the proportion of each category, so there is no standard.</p> <p>Video 3 Chapter 2</p> <p>ROC: receiver-operating characteristic curve, predicting something which has two values. outputs a probability or real value. <br />Four possibilities: true positive/false positive/true negative/ false negative<br />X axis = percent false positives<br />Y axis = percent true positives<br />A‘ closely approximates the area under the ROC curve, called AUC. A' only work for two categories. it's always higher than Kappa values. <br />precision = TP/(TP+FP); the probability that a data point classified as true is actually true.<br />recall = tp/(tp+fn); the probability that a data point that is actually true is classifies as true. </p> <p>Video 4 Chapter 2</p> <p>metrics for regressors: <br />linear correlation: Pearson's correlation. 1 is perfect, 0 none; -1 is perfectly negatively correlated. in between depends on the field. in physics correlation of 0.8 is weak. in education correlation of 0.3 is good. R^2 a measure of what percentage of variance in dependent measures. <br />MAD/RMSE: mean absolute deviation/root mean squared error. MAS tells the average amount to which the predictions deviate from the actual values. RMSE penalizes large deviation more than small deviation. Lower MAD/RMSE and high correlation is good model. High MAD/RMSE and low correlation(model values are in the right range, but model does not capture relative change) is bad model. <br />information criteria: 1. BIC value over 0 worse than expected given number of vairables. under 0, better than expected given number of variables. it's statistically equivalent to k-fold cross-validation for optimal k. 2. AIC an information critiera, make slightly different trade-off between goodness of fit and flexibility of fit. Equivalent to leave-out-one-cross-validation.</p> <p>Video 5 Chapter 2</p> <p>cross-validation and over-fitting<br />over-fitting: fitting to the noise as well as the signal. reducing over-fitting: fewer variable and less complex functions. No way to eliminating over-fitting.  groups: k-fold, pick a number K, split into this number of groups, quicker. Leave-out-one, every data point is a fold, more stable. <br />Flat cross-validation: each point has equal chance of being placed into each fold. <br />stratified cross-validation:biases fold selection so that some variable is equally represented in each fold. <br />Student-level cross-validation: no student's data is represent in two folds.seen as minimum cross-validation.</p> <p>Video 1 Chapter 4</p> <p>Bayersian knowledge tracing(BKT): classic approach for measuring tightly defined skill in online learning. goal is to measuring how well a student knows a specific skill/knowledge component at a specific time. Use: assess a student knowledge of skill. where each item corresponds to a single skill. <br />Assumption: each item must involve a single latent skill, each skill has four parameter, able to compute latent knowledge P(Ln)/the probability P(CORR) that the learner will get the item correct. Two-state learning model. <br />Classical BKT: two learning parameters:P(L0),P(T); two performance parameters: P(G), P(S).<br />predicting current student correctness formular<br />Parameter constraints:to avoid model degeneracy<br />conceptual idea behind knowledge tracing: by looking at whether a student's performance is correct, we can infer whether they know the skill. <br />three public tools: 1. BNT-SM: Bayes Net Toolkit-Student Modeling 2. Fitting BKT at scale 3. BKT-BF:BKT-Brute Force(Grid Search)</p> <p> </p>","","","","","","","","","","","","","","","","","","","","","","","","1","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TA4DJ6PS","videoRecording","2016","Georgia Tech","Cross Validation","","","","","https://www.youtube.com/watch?v=sFO2ff-gTh0","","2016-09-09","2019-09-17 21:46:21","2019-09-17 21:46:21","2016-09-09 19:37:11","","","","","","","","","","","","Youtube","","","","","","","","","","<p>cross validation</p> <p>higher order polynomial if the line does not good fit the all point.  <br />test set is how the system id ultimately going to be used. <br />The data being independent and identically distributed, the data all come from the same source. <br /> we want to do use a model that is complex enough to fit the data without causing problem on the test set. <br />pretend train data to test set.  For training data, split the data called folds then average all error together.</p>","","https://www.youtube.com/watch?v=sFO2ff-gTh0","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NAI2E38S","book","2019","Grolemund, Garrett","Hands-On Programming with R","","","","","https://rstudio-education.github.io/hopr/","This book will teach you how to program in R, with hands-on examples. I wrote it for non-programmers to provide a friendly introduction to the R language. You’ll learn how to load data, assemble and disassemble data objects, navigate R’s environment system, write your own functions, and use all of R’s programming tools. Throughout the book, you’ll use your newfound skills to solve practical data science problems.","2019-09-12","2019-09-17 21:46:21","2019-09-17 21:46:21","2019-09-12 17:12:28","","","","","","","","","","","","","","","","","","","rstudio-education.github.io","","","<p>Chapter 1</p> <p>operation: + - * /</p> <p>stored data: die &lt;- 1:4 ## die 1 2 3 4</p> <p>%*% inner multiplication  %o% outer multiplication</p> <p>Functions: 1. round(x, digits = #) 2. factorial() 3. mean() 4. sample(x, size, replace = TRUE / FALSE) #sample takes two arguments: a vector named x and a number named size. sample will return size elements from the vector. Replace = TRUE causes sample to sample with replacement. 5. sum() 6. roll()</p> <p>function constructor: function() {}</p> <p>Chapter 2</p> <p>packages: install.packages(""ggplot2"") ## qplot makes ""quick plots""</p> <p>library: library(""ggplot2"")</p> <p>replicate(10, roll())  ## 3 7 5 3 6 2 3 8 11 7  ### first replicate the number of times you wish to repeat and R command, and then give it the command you wish to repeat.</p> <p>Chapter 3</p> <p>die &lt;- c(1,2,3,4,5,6) ## die 1 2 3 4 5 6</p> <p>is. vector(die) ## TRUE  ### is. vector tests whether an object is an atomic vector.</p> <p>1. length() 2. sqrt() 3. class() ##character/numeric 4. Sys.time()</p> <p>typeof() ##know what type of object you are working with, some R functions refer to doubles as ""numerics"".</p> <p>int &lt;- c(-1L, 2L. 4L) ## int -1 2 4</p> <p>typeof(int)  ## ""integer""</p> <p>logicals: 3&gt;4 ## FALSE</p> <p>dimensions attribute: dim(die) &lt;- c(2,3) ## die<br />##          [,1]    [,2]    [,3] <br />## [1,]       1       3       5                          ###matrices<br />## [2,]       2       4       6                          ### matrix(die, nrow =2)</p> <p>coercion: logical &lt; number &lt; character<br />TRUE = 1, FALSE = 0<br />as. character(1) ##""1""<br />as. logical(1) ## TRUE<br />as. numeric(FALSE) ##0</p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p>","","https://rstudio-education.github.io/hopr/","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CV4QVCJ6","webpage","2019","Powell, V; Lehe, L","Principal Component Analysis explained visually","Explained Visually","","","","http://setosa.io/ev/principal-component-analysis/","","2019-09-12","2019-09-17 21:46:21","2019-09-17 21:46:21","2019-09-12 17:17:07","","","","","","","","","","","","","","","","","","","","","","<p>PCA: principal component analysis is a technique used to emphasize variation and bring out strong pattern in a dataset. Find the 2 principal components.</p> <p>2D example: PCA finds a new coordinate system in which every point has a new (x,y) value.</p> <p>3D example: drop one dimension, project the data into 2D and it is more clear.</p> <p>Eating in the UK( a 17D example): try to eliminate dimension and project the data into 2D.</p> <p> </p>","","http://setosa.io/ev/principal-component-analysis/","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""